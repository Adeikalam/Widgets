{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://datascientest.fr/train/assets/logo_datascientest.png\", style=\"height:150px\">\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<center><h1> Introduction au Deep Learning </h1></center>\n",
    "<center><h2> Concepts fondamentaux </h2></center>\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "> L'objectif de ce module de formation est de vous familiariser avec les concepts fondamentaux du *deep learning*. Ces concepts vous permettront de comprendre les algorithmes qui nous permettent de construire et entraîner un réseau de neurones. \n",
    ">\n",
    "> Ce module ne compte pas d'exercices pratiques comme les autres et ne sert qu'à illustrer ces concepts le plus clairement possible.\n",
    ">\n",
    "> Il n'y a donc aucun pré-requis technique pour aborder ce module à part un niveau très basique en algèbre linéaire et calcul différentiel.\n",
    "\n",
    "* Veuillez attendre la fin du chargement du notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fdf42400d74c3d90cd0f68296c2364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, bar_style='success', description='Loading :', max=11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "progress = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=11,\n",
    "    step=1,\n",
    "    description='Loading :',\n",
    "    bar_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    orientation='horizontal')\n",
    "\n",
    "\n",
    "def progress_complete(change):\n",
    "    if(progress.value == 11):\n",
    "        progress.description = \"Ready\"\n",
    "    else:\n",
    "        progress.description = \"Loading \"+ str(int((progress.value / 11)*100)) + \"%:\"\n",
    "    \n",
    "progress.observe(progress_complete)\n",
    "\n",
    "display(progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification grâce au produit scalaire usuel.\n",
    "\n",
    "> Le produit scalaire est utilisé pour la classification grâce à ses propriétés géométriques. Le résultat produit par le produit scalaire entre deux vecteurs est très facile à interpréter.\n",
    ">\n",
    "> Dans la figure interactive suivante, vous pouvez apercevoir un point et un vecteur. Le point **x** de couleur bleue et de coordonnées **${(x_1, x_2)}$** est le point que nous devons classifier. Le vecteur **w** de couleur verte et de coordonnées **${(w_1, w_2)}$** est le vecteur qui nous permettra de le classifier.\n",
    ">\n",
    "> La classification avec le produit scalaire se fait ainsi:\n",
    "> * Si le produit scalaire entre **x** et **w** est **positif**, **x sera classifié à 1** (de couleur bleue).\n",
    "> * Si le produit scalaire entre **x** et **w** est **négatif**, **x sera classifié à 0** (de couleur rouge).\n",
    ">\n",
    "> La **ligne verte perpendiculaire à w** représente tous les points du domaine tels que **le produit scalaire avec w vaut 0**. On appelle cette ligne la **frontière de décision** du problème de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": false,
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99f075dd454431e901ac14e82fa73d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(axes=[Axis(scale=LinearScale(max=5.0, min=-5.0)), Axis(orientation='vertical', scale=LinearScale(max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6091792b0b624ad9b64502d057c31eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=-2.0, description='x1', max=4.0, min=-4.0), FloatSlider(value=1.0, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyvolume as ipv\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import bqplot as bq\n",
    "import bqplot.pyplot as plt\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "\n",
    "######################################################################\n",
    "#                                                                    #\n",
    "#                  Classification using Dot Product                  #\n",
    "#                                                                    #\n",
    "######################################################################\n",
    "plt.clear()\n",
    "x = np.array([1.0, 0.0])\n",
    "\n",
    "w = np.array([0, 1.0])\n",
    "\n",
    "w_ort = np.array([-w[1], w[0]])\n",
    "w_ort = w_ort/np.linalg.norm(w_ort, ord = 2)\n",
    "\n",
    "#dot_fig = plt.figure()\n",
    "\n",
    "\n",
    "dot_lin_sc = bq.LinearScale(min = -5, max = 5)\n",
    "\n",
    "dot_x_point = plt.scatter(x = np.array([x[0]]),\n",
    "                     y = np.array([x[1]]),\n",
    "                     scales={'x': dot_lin_sc, 'y': dot_lin_sc},\n",
    "                     colors = ['blue'])\n",
    "\n",
    "dot_x_lineto_w = plt.plot(x = [np.dot(w, x)*w[0], x[0]],\n",
    "                      y = [np.dot(w, x)*w[1], x[1]],\n",
    "                      colors = ['red'],\n",
    "                      scales={'x': dot_lin_sc, 'y': dot_lin_sc},\n",
    "                      line_style = 'dashed'\n",
    "                      ) \n",
    "\n",
    "dot_x_proj_w = plt.plot(x = [np.dot(w, x)*w[0], 0],\n",
    "                    y = [np.dot(w, x)*w[1], 0],\n",
    "                    colors = ['red'],\n",
    "                    scales={'x': dot_lin_sc, 'y': dot_lin_sc},\n",
    "                    line_style = 'dashed')\n",
    "\n",
    "dot_w_line = plt.plot(x =[0, w[0], 0.8*w[0] - w[1]/10, w[0], 0.8*w[0] + w[1]/10],\n",
    "                  y = [0, w[1], 0.8*w[1] + w[0]/10, w[1], 0.8*w[1] - w[0]/10],\n",
    "                  scales={'x': dot_lin_sc, 'y': dot_lin_sc},\n",
    "                  colors = ['green'])\n",
    "\n",
    "dot_w_plane = plt.plot(x = [- w_ort[0]/np.linalg.norm(w_ort, ord = 2)*30, w_ort[0]/np.linalg.norm(w_ort, ord = 2)*30],\n",
    "                   y = [- w_ort[1]/np.linalg.norm(w_ort, ord = 2)*30, w_ort[1]/np.linalg.norm(w_ort, ord = 2)*30],\n",
    "                   scales={'x': dot_lin_sc, 'y': dot_lin_sc},\n",
    "                   colors = ['green'])\n",
    "\n",
    "dot_label_x = plt.label([\" \"],\n",
    "                    x = [x[0]],\n",
    "                    y = [x[1]],\n",
    "                    x_offset = -50,\n",
    "                    y_offset = -15,\n",
    "                    default_size = 12,\n",
    "                    font_weight = 'bolder',\n",
    "                    update_on_move = True,\n",
    "                    colors = [\"blue\"])\n",
    "\n",
    "dot_label_w = plt.label([\"w = (\"+ str(w[0])+\", \" +str(w[1]) + \")\"],\n",
    "                    x = [w[0]],\n",
    "                    y = [w[1]],\n",
    "                    x_offset = 10,\n",
    "                    y_offset = -10,\n",
    "                    default_size = 12,\n",
    "                    font_weight = 'bolder',\n",
    "                    colors = [\"green\"])\n",
    "\n",
    "dot_label_dot_xw = plt.label([\" \"],\n",
    "                    x = [w[0]],\n",
    "                    y = [w[1]],\n",
    "                    x_offset = 5,\n",
    "                    y_offset = 5,\n",
    "                    default_size = 24,\n",
    "                    font_weight = 'bolder',\n",
    "                    colors = [\"blue\"])\n",
    "\n",
    "\n",
    "dot_ax_x = bq.Axis(scale=dot_lin_sc,\n",
    "                grid_lines='solid')\n",
    "\n",
    "dot_ax_y = bq.Axis(scale=dot_lin_sc,\n",
    "                orientation='vertical',\n",
    "                grid_lines='solid')\n",
    "\n",
    "dot_fig = plt.Figure(marks = [dot_x_point, dot_x_lineto_w, dot_x_proj_w, dot_w_line,\n",
    "                              dot_w_plane, dot_label_x, dot_label_w, dot_label_dot_xw],\n",
    "                     axes = [dot_ax_x, dot_ax_y],\n",
    "                     title = \"Classification using Dot Product\")\n",
    "dot_fig.layout.height = '400px'\n",
    "dot_fig.layout.width = '400px'\n",
    "\n",
    "display(dot_fig)\n",
    "\n",
    "progress.value += 1\n",
    "\n",
    "@widgets.interact(\n",
    "          x1 = widgets.FloatSlider(min=-4, max=4, step=0.1, value=-2),\n",
    "          x2 = widgets.FloatSlider(min=-4, max=4, step=0.1, value=1.0),\n",
    "          w1 = widgets.FloatSlider(min=-4, max=4, step=0.1, value=0),\n",
    "          w2 = widgets.FloatSlider(min=-4, max=4, step=0.1, value=2))\n",
    "\n",
    "def dot_classification(x1, x2, w1, w2):\n",
    "    dot_x_point.x = [x1]\n",
    "    dot_x_point.y = [x2]\n",
    "    \n",
    "    w = np.array([w1, w2])\n",
    "    w_ort = np.array([-w[1], w[0]])\n",
    "    w_ort = w_ort/np.linalg.norm(w_ort, ord = 2)\n",
    "    \n",
    "    dot_w_line.x =[0, w[0], 0.8*w[0] - w[1]/10, w[0], 0.8*w[0] + w[1]/10]\n",
    "    dot_w_line.y = [0, w[1], 0.8*w[1] + w[0]/10, w[1], 0.8*w[1] - w[0]/10]\n",
    "    \n",
    "    dot_w_plane.x = [- w_ort[0]/np.linalg.norm(w_ort, ord = 2)*30, w_ort[0]/np.linalg.norm(w_ort, ord = 2)*30]\n",
    "    dot_w_plane.y = [- w_ort[1]/np.linalg.norm(w_ort, ord = 2)*30, w_ort[1]/np.linalg.norm(w_ort, ord = 2)*30]\n",
    "    \n",
    "    dot_label_w.x = [w1]\n",
    "    dot_label_w.y = [w2]\n",
    "    dot_label_w.text = [\"w = (\" + str(w1) + \", \" + str(w2) + \")\"]\n",
    "    \n",
    "    dot_label_x.x = [x1]\n",
    "    dot_label_x.y = [x2]\n",
    "    dot_label_x.text = [\"x = (\" + str(x1) + \", \" + str(x2) + \")\"]\n",
    "    \n",
    "    norm_w = np.linalg.norm(w, ord = 2)\n",
    "    \n",
    "    dot_label_dot_xw.text = [\"<w,x> = \" + str(np.round(np.dot(w, np.array([x1, x2])), 3))] \n",
    "    dot_label_dot_xw.x = [np.dot(w/norm_w, np.array([x1, x2]))*(w[0]/norm_w)]\n",
    "    dot_label_dot_xw.y = [np.dot(w/norm_w, np.array([x1, x2]))*(w[1]/norm_w)]\n",
    "    \n",
    "    if(np.dot(w/norm_w, np.array([x1, x2])) < 0):\n",
    "        dot_label_x.colors = ['red']\n",
    "        dot_label_dot_xw.colors = ['red']\n",
    "        dot_x_point.colors = ['red']\n",
    "    elif(np.dot(w/norm_w, np.array([x1, x2])) > 0):\n",
    "        dot_label_x.colors = ['blue']\n",
    "        dot_label_dot_xw.colors = ['blue']\n",
    "        dot_x_point.colors = ['blue']\n",
    "    else:\n",
    "        dot_label_x.colors = ['green']\n",
    "        dot_label_dot_xw.colors = ['green']\n",
    "        dot_x_point.colors = ['green']\n",
    "    \n",
    "    dot_x_lineto_w.x = [np.dot(w/norm_w, np.array([x1, x2]))*(w[0]/norm_w), x1]\n",
    "    dot_x_lineto_w.y = [np.dot(w/norm_w, np.array([x1, x2]))*(w[1]/norm_w), x2]\n",
    "    \n",
    "    dot_x_proj_w.x = [0,np.dot(w/norm_w, np.array([x1, x2]))*(w[0]/norm_w)]\n",
    "    dot_x_proj_w.y = [0, np.dot(w/norm_w, np.array([x1, x2]))*(w[1]/norm_w)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Le résultat du produit scalaire entre x et w peut s'interpréter géométriquement:\n",
    "> * Si le produit scalaire entre x et w est positif, alors x est **\"au dessus\"** (dans la direction de w) de la frontière de décision.\n",
    "> * Si le produit scalaire entre x et w est négatif, alors x est **\"en dessous\"** (dans la direction de w) de la frontière de décision.\n",
    "\n",
    "### Séparabilité Linéaire\n",
    "\n",
    "> La notion de séparabilité linéaire d'une base de données est fondamentale pour utiliser la classification par produit scalaire. \n",
    ">\n",
    ">\n",
    "> La figure suivante correspond à la base de données **Iris** qui contient 2 variables: `Sepal Width` et `Sepal Length` correspondant à la largeur et longueur de sépale de deux espèces d'iris différentes. Le problème de classification est le suivant:\n",
    "> * **Pouvons-nous à partir de ces deux variables déterminer l'espèce d'une fleur ?**\n",
    ">\n",
    "> Les **points verts** de la figure correspondent aux fleurs d'espèce **iris setosa** et les **points oranges** correspondent aux fleurs d'espèce **iris virginica**. (La base de données a été normalisée pour obtenir une meilleure visualisation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": false,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d8c4728dbf472e83c5ab83d3752e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(axes=[Axis(label='Sepal Length', scale=LinearScale(max=4.0, min=-4.0)), Axis(label='Sepal Width', orien…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "plt.clear()\n",
    "iris_X = datasets.load_iris()['data']\n",
    "iris_y = datasets.load_iris()['target']\n",
    "iris_y[iris_y == 2] = 1\n",
    "\n",
    "colors = []\n",
    "for i in range(iris_y.shape[0]):\n",
    "    if (iris_y[i] == 0):\n",
    "        colors.append('green')\n",
    "    else:\n",
    "        colors.append('orange')\n",
    "        \n",
    "scaled = iris_X[:,:2] - np.array([np.mean(iris_X[:,0]), np.mean(iris_X[:,1])])\n",
    "scaled = scaled / np.array([np.std(iris_X[:,0]), np.std(iris_X[:,1])])\n",
    "\n",
    "sep1_x_sc = plt.LinearScale(min = -4, max = 4)\n",
    "sep1_y_sc = plt.LinearScale(min = -4, max = 4)\n",
    "     \n",
    "sep1_ax_x = plt.Axis(scale=sep1_x_sc,\n",
    "                grid_lines='solid',\n",
    "                label='Sepal Length')\n",
    "\n",
    "sep1_ax_y = plt.Axis(scale=sep1_y_sc,\n",
    "                orientation='vertical',\n",
    "                grid_lines='solid',\n",
    "                label='Sepal Width')\n",
    "                        \n",
    "                          # Scatter plot\n",
    "    \n",
    "sep1_bar = plt.Scatter(x = scaled[:,0],\n",
    "                       y = scaled[:,1]-1,\n",
    "                       colors = colors,\n",
    "                       default_size = 10,\n",
    "                       scales={'x': sep1_x_sc, 'y': sep1_y_sc})\n",
    "\n",
    "\n",
    "sep1_f = plt.Figure(marks=[sep1_bar],\n",
    "               axes=[sep1_ax_x, sep1_ax_y],\n",
    "               title='Iris Dataset',\n",
    "               legend_location='bottom-right')\n",
    "\n",
    "sep1_f.layout.height = '400px'\n",
    "sep1_f.layout.width = '400px'\n",
    "\n",
    "progress.value += 1\n",
    "\n",
    "display(sep1_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "> Pour résoudre ce problème **géométriquement** avec la classification par produit scalaire, nous pouvons reformuler la question de la manière suivante:\n",
    "> * **Existe-t-il une frontière de décision linéaire qui nous permettrait de séparer les deux espèces ?**\n",
    ">\n",
    "* Trouver à l'aide de la figure interactive suivante un vecteur w définissant une frontière de décision **séparant les points verts des points oranges**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6510702f877148a1b56b8a63fc5192fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(axes=[Axis(label='Sepal Length', scale=LinearScale(max=4.0, min=-4.0)), Axis(label='Sepal Width', orien…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa44a9de35d84e9aad97dc1fb0190bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='w1', max=4.0, min=-4.0, step=0.11), FloatSlider(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################################\n",
    "#                                                                    #\n",
    "#                       Interactive Loss Plot                        #\n",
    "#                                                                    #\n",
    "######################################################################\n",
    "\n",
    "\n",
    "                            # Data\n",
    "    \n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "iris_X = datasets.load_iris()['data']\n",
    "iris_y = datasets.load_iris()['target']\n",
    "iris_y[iris_y == 2] = 1\n",
    "\n",
    "colors = []\n",
    "for i in range(iris_y.shape[0]):\n",
    "    if (iris_y[i] == 0):\n",
    "        colors.append('green')\n",
    "    else:\n",
    "        colors.append('orange')\n",
    "        \n",
    "scaled = iris_X[:,:2] - np.array([np.mean(iris_X[:,0]), np.mean(iris_X[:,1])])\n",
    "scaled = scaled / np.array([np.std(iris_X[:,0]), np.std(iris_X[:,1])])\n",
    "\n",
    "################################################################################    \n",
    "    \n",
    "                            # Scales\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "sep2_x_sc = plt.LinearScale(min = -4, max = 4)\n",
    "sep2_y_sc = plt.LinearScale(min = -4, max = 4)\n",
    "     \n",
    "sep2_ax_x = plt.Axis(scale=sep2_x_sc,\n",
    "                grid_lines='solid',\n",
    "                label='Sepal Length')\n",
    "\n",
    "sep2_ax_y = plt.Axis(scale=sep2_y_sc,\n",
    "                orientation='vertical',\n",
    "                grid_lines='solid',\n",
    "                label='Sepal Width')\n",
    "                        \n",
    "                          # Scatter plot\n",
    "    \n",
    "sep2_bar = plt.Scatter(x = scaled[:,0],\n",
    "                  y = scaled[:,1]-1,\n",
    "                  colors = colors,\n",
    "                  default_size = 10,\n",
    "                  scales={'x': sep2_x_sc, 'y': sep2_y_sc})\n",
    "\n",
    "                             # Vector\n",
    "    \n",
    "w1, w2 = 1.0, 1.0\n",
    "w = np.array([w1, w2])\n",
    "\n",
    "sep2_vector_line = plt.Lines(x = np.array([0, w1]),\n",
    "                        y = np.array([0, w2]),\n",
    "                        colors = ['red', 'red'],\n",
    "                        scales={'x': sep2_x_sc, 'y': sep2_y_sc})\n",
    "\n",
    "sep2_vector_label = plt.Label(x = [w1],\n",
    "                         y = [w2],\n",
    "                         text = ['(w1, w2)'],\n",
    "                         size = [10])\n",
    "\n",
    "sep2_vector_plane = plt.Lines(x = [-30*(w2 / np.linalg.norm(w)), 30*(w2 / np.linalg.norm(w))],\n",
    "                         y = [30*(w1 / np.linalg.norm(w)), -30*(w1 / np.linalg.norm(w))],\n",
    "                         colors = ['red', 'red'],\n",
    "                         scales={'x': sep2_x_sc, 'y': sep2_y_sc})\n",
    "\n",
    "sep2_f = plt.Figure(marks=[sep2_bar, sep2_vector_line, sep2_vector_label, sep2_vector_plane],\n",
    "               axes=[sep2_ax_x, sep2_ax_y],\n",
    "               title='Iris Dataset',\n",
    "               legend_location='bottom-right')\n",
    "\n",
    "sep2_f.layout.height = '400px'\n",
    "sep2_f.layout.width = '400px'\n",
    "\n",
    "display(sep2_f)\n",
    "\n",
    "progress.value += 1\n",
    "\n",
    "@widgets.interact(\n",
    "          w1 = widgets.FloatSlider(min=-4, max=4, step=0.11, value=1.0),\n",
    "          w2 = widgets.FloatSlider(min=-4, max=4, step=0.11, value=1.0))\n",
    "\n",
    "                  # Fonction qui va interagir avec les widgets\n",
    "    \n",
    "def h(w1, w2):\n",
    "    sep2_vector_line.x = [0, w1, 0.8*w1 - w2/10, w1, 0.8*w1 + w2/10]\n",
    "    sep2_vector_line.y = [0, w2, 0.8*w2 + w1/10, w2, 0.8*w2 - w1/10]\n",
    "    w = np.array([w1, w2])\n",
    "    sep2_vector_plane.x = [-30*w2 / np.linalg.norm(w), 30*w2 / np.linalg.norm(w)]\n",
    "    sep2_vector_plane.y = [30*w1 / np.linalg.norm(w), -30*w1 / np.linalg.norm(w)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Une solution possible est le vecteur `w = (-1.8, 0.95)` qui définit une frontière de décision **linéaire** séparant **parfaitement** les deux groupes d'individus. On dit alors que la base de données est **linéairement séparable**.\n",
    ">\n",
    "> Dans ce cas particulier, la frontière de décision porte le nom d'**hyperplan séparateur**. Nous utilisons cette dénomination car les points définissant la frontière de décision sont les points satisfaisant l'**équation de plan** ${\\{ x = (x_1,x_2)\\in \\mathbb{R}^2 : \\langle x, w \\rangle = x_1 w_1 + x_2 w_2 = 0\\} }$\n",
    "\n",
    "### Fonction de Perte\n",
    "\n",
    "> Nous avons vu que nous pouvons trouver pour la base de données Iris un hyperplan séparant parfaitement les deux espèces de fleur. Cependant, cette solution a été trouvée visuellement.\n",
    "> * **Comment trouver mathématiquement un hyperplan séparateur?**\n",
    ">\n",
    "> Il faut d'abord trouver un moyen de quantifier la qualité de la séparation des espèces. Une des possibilités les plus simple est de **compter le nombre d'erreurs de classification que nous ferions en utilisant un vecteur spécifique**.\n",
    ">\n",
    "> Supposons que notre base de données contient $n$ points ${X = (x_i)_{i = 1, 2,..., n} \\in \\mathbb{R}^d}$ et qu'à chacun de ses points sont associées les valeurs ${Y = (y_i)_{i = 1,2,...,n} \\in \\{0,1\\}}$ correspondant au groupe auquel appartient le point $x_i$.\n",
    ">\n",
    "> Dans notre exemple, la classe 1 correspondrait à l'espèce *iris setosa* et la classe 0 à l'espèce *iris virginica*.\n",
    ">\n",
    "> Mathématiquement, la classification d'un individu $x_i$ par un vecteur $w$ se ferait par une fonction $f$ définie ainsi:\n",
    ">\n",
    ">$${f(x_i, w) = \\mathbb{1}_{\\langle x,w \\rangle \\geq 0} = \\begin{cases} 1 & \\mbox{si } \\langle x,w \\rangle \\geq 0 \\\\  0 & \\mbox{si } \\langle x,w \\rangle < 0 \\end{cases}}$$\n",
    ">\n",
    "> Ainsi, le nombre d'erreurs peut être calculé par une fonction de ${w = (w_1, w_2)}$, $X$ et $Y$ qui s'écrirait ainsi:\n",
    ">\n",
    "> $${ g(w,X,Y) = \\sum_{i = 1}^{n}\\mathbb{1}_{f(x_i, w)\\neq y_i} }$$\n",
    ">\n",
    "> Cette fonction nous permet de définir un critère pour déterminer la meilleure solution à notre problème de classification. Les fonctions de ce type s'appellent des **fonctions de perte** (*loss function* en anglais). \n",
    ">\n",
    "> Plus la valeur de cette fonction est basse, plus notre fonction de classification est perfromante. **Minimiser cette fonction de perte par rapport au vecteur w est donc équivalent à trouver un hyperplan séparateur**.\n",
    ">\n",
    "* A l'aide de la figure interactive suivante, minimiser la fonction de perte associée à la classification par le vecteur w défini par les curseurs de défilement.\n",
    "\n",
    "\n",
    "* Essayer maintenant de maximiser cette fonction de perte. Quel vecteur optimal obtenez-vous? Pourquoi?\n",
    "\n",
    "> <div class=\"alert alert-success\">\n",
    "<i class=\"fa fa-question-circle\"></i> &emsp; \n",
    "A l'aide de votre souris vous pouvez faire pivoter la figure 3d et zoomer/dézoomer dessus.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hide_input": false,
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05345eb587274e9099c48ede062053fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Figure(axes=[Axis(label='Sepal Length', scale=LinearScale(max=4.0, min=-4.0)), Axis(label='Sepa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df110f70281848ef8f2ba38362e874cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='w1', max=4.0, min=-4.0, step=0.11), FloatSlider(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyvolume as ipv\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from bqplot import pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "def plot_3d_function(function, resolution = 200, x_range = [-10, 10], y_range = [-10, 10]):\n",
    "    n = resolution\n",
    "    x = np.linspace(x_range[0], x_range[1], n)\n",
    "    y = np.linspace(y_range[0], y_range[1], n)\n",
    "    coords = []\n",
    "\n",
    "    i = 0\n",
    "    while(i < n):\n",
    "        for j in range(n):\n",
    "            coords += [[x[i], y[j], function(x[i],y[j])]]\n",
    "        for j in range(n):\n",
    "            coords += [[x[i+1], y[n-j-1], function(x[i+1],y[n-j-1])]]\n",
    "        i = i+2\n",
    "    \n",
    "    coords = np.array(coords)\n",
    "    coords_x = coords[:,0]\n",
    "    coords_y = coords[:,1]\n",
    "    coords_z = coords[:,2]\n",
    "    \n",
    "    return coords_x, coords_y, coords_z\n",
    "\n",
    "######################################################################\n",
    "#                                                                    #\n",
    "#                       Interactive Loss Plot                        #\n",
    "#                                                                    #\n",
    "######################################################################\n",
    "\n",
    "\n",
    "                            # Data\n",
    "    \n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "iris_X = datasets.load_iris()['data']\n",
    "iris_y = datasets.load_iris()['target']\n",
    "iris_y[iris_y == 2] = 1\n",
    "\n",
    "colors = []\n",
    "for i in range(iris_y.shape[0]):\n",
    "    if (iris_y[i] == 0):\n",
    "        colors.append('green')\n",
    "    else:\n",
    "        colors.append('orange')\n",
    "        \n",
    "scaled = iris_X[:,:2] - np.array([np.mean(iris_X[:,0]), np.mean(iris_X[:,1])])\n",
    "scaled = scaled / np.array([np.std(iris_X[:,0]), np.std(iris_X[:,1])])\n",
    "\n",
    "################################################################################    \n",
    "    \n",
    "                            # Scales\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "loss_x_sc = plt.LinearScale(min = -4, max = 4)\n",
    "loss_y_sc = plt.LinearScale(min = -4, max = 4)\n",
    "     \n",
    "loss_ax_x = plt.Axis(scale=loss_x_sc,\n",
    "                grid_lines='solid',\n",
    "                label='Sepal Length')\n",
    "\n",
    "loss_ax_y = plt.Axis(scale=loss_y_sc,\n",
    "                orientation='vertical',\n",
    "                grid_lines='solid',\n",
    "                label='Sepal Width')\n",
    "                        \n",
    "                          # Scatter plot\n",
    "    \n",
    "loss_bar = plt.Scatter(x = scaled[:,0],\n",
    "                  y = scaled[:,1]-1,\n",
    "                  colors = colors,\n",
    "                  default_size = 10,\n",
    "                  scales={'x': loss_x_sc, 'y': loss_y_sc})\n",
    "\n",
    "                             # Vector\n",
    "    \n",
    "w1, w2 = 1.0, 1.0\n",
    "w = np.array([w1, w2])\n",
    "\n",
    "loss_vector_line = plt.Lines(x = np.array([0, w1]),\n",
    "                        y = np.array([0, w2]),\n",
    "                        colors = ['red', 'red'],\n",
    "                        scales={'x': loss_x_sc, 'y': loss_y_sc})\n",
    "\n",
    "loss_vector_label = plt.Label(x = [w1],\n",
    "                         y = [w2],\n",
    "                         text = ['(w1, w2)'],\n",
    "                         size = [10])\n",
    "\n",
    "loss_vector_plane = plt.Lines(x = [-4*(w2 / np.linalg.norm(w)), 4*(w2 / np.linalg.norm(w))],\n",
    "                         y = [4*(w1 / np.linalg.norm(w)), -4*(w1 / np.linalg.norm(w))],\n",
    "                         colors = ['red', 'red'],\n",
    "                         scales={'x': loss_x_sc, 'y': loss_y_sc})\n",
    "\n",
    "loss_f = plt.Figure(marks=[loss_bar, loss_vector_line, loss_vector_label, loss_vector_plane],\n",
    "               axes=[loss_ax_x, loss_ax_y],\n",
    "               title='Iris Dataset',\n",
    "               legend_location='bottom-right')\n",
    "\n",
    "loss_f.layout.height = '400px'\n",
    "loss_f.layout.width = '400px'\n",
    "\n",
    "\n",
    "def loss_function(w1, w2):\n",
    "    loss = 0\n",
    "    p = 0\n",
    "    for i in range(iris_y.shape[0]):\n",
    "        \n",
    "        if (w1*scaled[:,0][i] + w2*(scaled[:,1][i] - 1) > 0):\n",
    "            prediction = 0\n",
    "        else:\n",
    "            prediction = 1\n",
    "        loss += np.abs(prediction - iris_y[i])\n",
    "    return loss/iris_y.shape[0]\n",
    "\n",
    "loss3d_f = ipv.figure(width = 400, height = 400)\n",
    "x, y, z = plot_3d_function(loss_function, resolution = 80, x_range = [-4, 4], y_range = [-4, 4])\n",
    "loss3d_plott = ipv.plot(x,y,z, color = 'blue')\n",
    "\n",
    "\n",
    "point_colors = np.zeros((2,3))\n",
    "point_colors[0] = np.array([255,255,255])\n",
    "point_colors[1] = np.array([255, 0, 0])\n",
    "\n",
    "loss3d_point = ipv.scatter(x = np.array([w1, w1]),\n",
    "                    y = np.array([w2, w2]),\n",
    "                    z = np.array([loss_function(w1, w2), loss_function(w1, w2)]),\n",
    "                    size = 10\n",
    "                   )\n",
    "loss3d_point.geo = \"sphere\"\n",
    "\n",
    "loss3d_f.xlabel = \"w1\"\n",
    "loss3d_f.ylabel = \"w2\"\n",
    "loss3d_f.zlabel = \"loss\"\n",
    "loss3d_f.animation = 0             # on enlève les animations  \n",
    "loss3d_f.animation_exponent = 0\n",
    "\n",
    "\n",
    "from ipywidgets import HBox\n",
    "display(HBox([loss_f, loss3d_f]))\n",
    "\n",
    "time.sleep(1)\n",
    "loss3d_f.camera.position = (0, 0, 0)\n",
    "loss3d_f.camera.position = (0, -2, 0)\n",
    "            \n",
    "progress.value += 1\n",
    "@widgets.interact(\n",
    "          w1 = widgets.FloatSlider(min=-4, max=4, step=0.11, value=1.0),\n",
    "          w2 = widgets.FloatSlider(min=-4, max=4, step=0.11, value=1.0))\n",
    "\n",
    "                  # Fonction qui va interagir avec les widgets\n",
    "    \n",
    "def h(w1, w2):\n",
    "    loss_vector_line.x = [0, w1, 0.8*w1 - w2/10, w1, 0.8*w1 + w2/10]\n",
    "    loss_vector_line.y = [0, w2, 0.8*w2 + w1/10, w2, 0.8*w2 - w1/10]\n",
    "    w = np.array([w1, w2])\n",
    "    loss_vector_plane.x = [-30*w2 / np.linalg.norm(w), 30*w2 / np.linalg.norm(w)]\n",
    "    loss_vector_plane.y = [30*w1 / np.linalg.norm(w), -30*w1 / np.linalg.norm(w)]\n",
    "    loss3d_point.x, loss3d_point.y, loss3d_point.z = np.array([w1,w1]), np.array([w2,w2]), np.array([loss_function(w1, w2)+ 0.0,0.0+ loss_function(w1, w2)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'algorithme du Perceptron\n",
    "\n",
    "> Les étapes que nous venons de suivre peuvent être automatisées dans un algorithme qui s'appelle l'algorithme du **Perceptron** inventé en 1957 par Frank Rosenblatt à l'université de Cornell. Le vocabulaire spécifique à cet algorithme est le suivant:\n",
    "> * Le vecteur $w$ définissant l'hyperplan séparateur porte le nom de **vecteur de poids** (*weight vector* en anglais).\n",
    "> * Le vecteur $x$ correspondant à un individu à classifier porte le nom de **vecteur d'entrée** (*input vector* en anglais).\n",
    ">\n",
    "> En suivant cette terminologie, le produit scalaire entre $x$ et $w$ peut être interprété comme une somme pondérée des features de x.\n",
    ">\n",
    "> Une autre subtilité de l'algorithme du perceptron est que le premier feature de $x$ aura **systématiquement la valeur $1$**. Ce feature artificiel sert en fait à décaler l'hyperplan séparateur dans l'espace d'une certaine valeur que l'on appelera **\"biais\"** (*bias term* en anglais).\n",
    ">\n",
    "> L'équation définissant l'hyperplan séparateur devient alors: \n",
    "> $$ \\langle x, w \\rangle + biais = 0$$\n",
    ">\n",
    ">\n",
    ">Dans la figure interactive suivante, vous pouvez apercevoir l'effet de chacune des coordonnées du vecteur de poids $w = (w_1, w_2, w_3)$ et du biais $b$:\n",
    "> * Le **vecteur vert** correspond au vecteur $w = (w1, w2, w3)$.\n",
    ">\n",
    ">\n",
    "> * Le **plan quadrillé rouge** correspond au plan d'équation $\\langle x, w \\rangle + biais = 0$.\n",
    ">\n",
    ">\n",
    "> * Les points **verts clair** correspondent au points tels que $ \\langle x, w \\rangle + biais \\geq 0$.\n",
    ">\n",
    ">\n",
    "> * Les points **bleus** correspondent au points tels que $ \\langle x, w \\rangle + biais \\lt 0$.\n",
    ">\n",
    "> Le curseur de défilement `resolution` permet de définir la résolution du quadrillage de l'hyperplan définit par $w$ et $biais$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide_input": false,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d396dbde9f0e4097bc614e32a45793a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(animation=0.0, animation_exponent=0.0, camera=PerspectiveCamera(fov=46.0, position=(0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2cff8cf7704ee0b084c26bcd1bcc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='w1', max=5.0, min=-5.0, step=0.3), FloatSlider(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyvolume as ipv\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from bqplot import pyplot as plt\n",
    "import time\n",
    "\n",
    "################################################################################\n",
    "#                                                                              #\n",
    "#                            Fonctions utilitaires                             #\n",
    "#                                                                              #\n",
    "################################################################################\n",
    "\n",
    "# Fonction qui génère les coordonnées x,y,z pour dessiner le vecteur en forme de flèche\n",
    "\n",
    "def plot_3d_vector(w1, w2, w3, bias = 0, radius = 0.5, length = 1, resolution = 100):\n",
    "    # Vecteurs du plan \n",
    "    w = np.array([w1, w2, w3])\n",
    "    w  =length * w / np.linalg.norm(w, ord = 2)\n",
    "    p1 = np.array([0, -w3, w2])                     \n",
    "    p2 = np.array([-(w2*w2/w3 + w3)/w1, w2/w3, 1])\n",
    "\n",
    "    p1 = p1 / np.linalg.norm(p1, ord = 2)\n",
    "    p2 = p2 / np.linalg.norm(p2 , ord = 2)\n",
    "    \n",
    "    # Coordonnées des deux cercles\n",
    "    if(resolution % 2 == 0):\n",
    "        n_thetas = resolution + 1\n",
    "    else:\n",
    "        n_thetas = resolution\n",
    "    \n",
    "    thetas = np.linspace(0, 2*np.pi, n_thetas)\n",
    "   \n",
    "    base_circle = np.array([radius * (p1 * np.cos(thetas[i]) + p2 * np.sin(thetas[i])) for i in range(n_thetas)])\n",
    "\n",
    "    top_circle_1 = base_circle + w * 0.5\n",
    "\n",
    "    top_circle_2 = np.array([(radius * 1.5) * (p1 * np.cos(thetas[i]) + p2 * np.sin(thetas[i])) for i in range(n_thetas)])\n",
    "    top_circle_2 = top_circle_2 + w * 0.5\n",
    "    \n",
    "    # Coordonnées de la trajectoire du plot\n",
    "    \n",
    "    circles = [top_circle_1[i,:] for i in range(n_thetas)]\n",
    "\n",
    "    i = 0\n",
    "    while(i < n_thetas-2):\n",
    "        circles += [top_circle_1[i,:], top_circle_1[i+1,:], base_circle[i+1,:], base_circle[i+2,:]]\n",
    "        i += 2\n",
    "    \n",
    "        \n",
    "    circles += [base_circle[i,:] for i in range(n_thetas)]    \n",
    "    circles += [top_circle_1[0,:]]\n",
    "    i = 0\n",
    "    while(i < n_thetas-2):\n",
    "        circles += [top_circle_1[i,:], top_circle_1[i+1,:], top_circle_2[i+1,:], top_circle_2[i+2,:]]\n",
    "        i += 2\n",
    "    \n",
    "    circles += [top_circle_2[0,:]]\n",
    "    circles += [top_circle_2[i,:] for i in range(n_thetas)] \n",
    "    \n",
    "    i = 0\n",
    "    while(i < n_thetas-2):\n",
    "        circles += [w, top_circle_2[i,:], w, top_circle_2[i+1,:]]\n",
    "        i += 2\n",
    "    \n",
    "    circles = np.array(circles)    \n",
    "    \n",
    "    circles_x = circles[:,0]\n",
    "    circles_y = circles[:,1]\n",
    "    circles_z = circles[:,2] - bias/w3    \n",
    "    \n",
    "    return circles_x, circles_y, circles_z                          \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Dimensions du plan       \n",
    "d1 = 20                                                                     \n",
    "d2 = 20                                          \n",
    "resolution = 50\n",
    "\n",
    "################################################################################\n",
    "#                                                                              #\n",
    "#                               Initialisation                                 #\n",
    "#                                                                              #\n",
    "################################################################################\n",
    "\n",
    "                      # Vecteur définissant le plan\n",
    "\n",
    "w1, w2, w3 = 1.0, 1.0, 1.0   # vecteur orthogonal au plan\n",
    "\n",
    "\n",
    "p1 = np.array([0, -w3, w2])    # vecteurs du plan pour trouver les 4 coins\n",
    "p2 = np.array([-(w2*w2/w3 + w3)/w1, w2/w3, 1])\n",
    "\n",
    "p1 = d1 * p1 / np.linalg.norm(p1, ord = 2)            \n",
    "p2 = d2 * p2 / np.linalg.norm(p2 , ord = 2)\n",
    "\n",
    "                            # 4 coins du plan\n",
    "point2 = p1 + p2          \n",
    "point3 = p1 - p2\n",
    "point4 = - point2\n",
    "point1 = - point3\n",
    "\n",
    "                 # Coordonnées pour dessiner la surface avec un grillage\n",
    "\n",
    "L = np.linspace(0, 1, resolution)\n",
    "L1 = []     # coordonnées x des points du grillage  \n",
    "L2 = []     # y\n",
    "L3 = []     # z\n",
    "\n",
    "for i in range(len(L)-1):\n",
    "    i = len(L)-1-i\n",
    "    L1 += [point1[0]*L[i]+point4[0]*(1-L[i]),point2[0]*L[i]+point3[0]*(1-L[i]),point2[0]*L[i-1]+point3[0]*(1-L[i-1])]\n",
    "    L2 += [point1[1]*L[i]+point4[1]*(1-L[i]),point2[1]*L[i]+point3[1]*(1-L[i]),point2[1]*L[i-1]+point3[1]*(1-L[i-1])]\n",
    "    L3 += [point1[2]*L[i]+point4[2]*(1-L[i]),point2[2]*L[i]+point3[2]*(1-L[i]),point2[2]*L[i-1]+point3[2]*(1-L[i-1])]\n",
    "L1 += [point4[0]]\n",
    "L2 += [point4[1]]\n",
    "L3 += [point4[2]]\n",
    "for i in range(len(L)-1):\n",
    "    i = len(L)-1-i\n",
    "    L1 += [point4[0]*L[i]+point3[0]*(1-L[i]),point1[0]*L[i]+point2[0]*(1-L[i]),point1[0]*L[i-1]+point2[0]*(1-L[i-1])]\n",
    "    L2 += [point4[1]*L[i]+point3[1]*(1-L[i]),point1[1]*L[i]+point2[1]*(1-L[i]),point1[1]*L[i-1]+point2[1]*(1-L[i-1])]\n",
    "    L3 += [point4[2]*L[i]+point3[2]*(1-L[i]),point1[2]*L[i]+point2[2]*(1-L[i]),point1[2]*L[i-1]+point2[2]*(1-L[i-1])]\n",
    "\n",
    "                      # Initialisation de la figure\n",
    "\n",
    "d3plane_fig = ipv.figure()\n",
    "\n",
    "                # Coordonnées d'un nuage de points aléatoire\n",
    "    \n",
    "scat_x, scat_y, scat_z = np.random.normal(0, 5, (3,100))\n",
    "\n",
    "     # Couleurs des points (bleu si classification positive / vert sinon)\n",
    "    \n",
    "cross_prods = np.array([np.dot(np.array([scat_x[i], scat_y[i], scat_z[i]]),np.array([w1, w2, w3])) for i in range(100)])\n",
    "colors = np.zeros((100,3))\n",
    "colors[np.where(cross_prods < 0)] = np.array([0, 0, 255])\n",
    "colors[np.where(cross_prods >= 0)] = np.array([0, 255, 0])\n",
    "\n",
    "                      # Scatterplot aléatoire\n",
    "\n",
    "d3plane_scat = ipv.scatter(scat_x, scat_y, scat_z, color = colors)\n",
    "\n",
    "                       # Plot de la surface\n",
    "    \n",
    "d3plane_xdd = ipv.plot(np.array(L1),np.array(L2),np.array(L3))\n",
    "\n",
    "                     # Plot du vecteur directeur\n",
    "\n",
    "vect_x, vect_y, vect_z = plot_3d_vector(w1, w2, w3, resolution = 10, length = 5)\n",
    "\n",
    "d3plane_vect = ipv.plot(vect_x, vect_y, vect_z, color = 'green')\n",
    "\n",
    "                         # Styling de la figure\n",
    "    \n",
    "d3plane_fig.animation = 0             # on enlève les animations  \n",
    "d3plane_fig.animation_exponent = 0\n",
    "\n",
    "ipv.xyzlim(-15,15)           # étendue des axes x,y,z\n",
    "\n",
    "d3plane_scat.geo = \"sphere\"         # glyphe sphere pour les points du nuage aléatoire\n",
    "\n",
    "ipv.show()       \n",
    "\n",
    "progress.value += 1\n",
    "\n",
    "################################################################################\n",
    "#                                                                              #\n",
    "#                            Partie interactive                                #\n",
    "#                                                                              #\n",
    "################################################################################\n",
    "                    \n",
    "               # Sliders pour les coordonnées du vecteur + biais \n",
    "\n",
    "#:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:#\n",
    "#                                                                                            #\n",
    "#               Se débrouiller pour ne mettre aucune des coordonnées de w à 0                #\n",
    "#                                                                                            #\n",
    "#:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:DANGER:#      \n",
    "\n",
    "@widgets.interact(\n",
    "          w1 = widgets.FloatSlider(min=-5, max=5, step=0.3, value=1.0),\n",
    "          w2 = widgets.FloatSlider(min=-5, max=5, step=0.3, value=1.0),\n",
    "          w3 = widgets.FloatSlider(min=-5, max=5, step=0.3, value=1.0),\n",
    "          bias = widgets.FloatSlider(min = -10, max = 10, step = 0.2, value = 0.0),\n",
    "          resolution = widgets.IntSlider(min = 10, max = 120, step = 10, value = 70))\n",
    "\n",
    "                  # Fonction qui va interagir avec les widgets\n",
    "    \n",
    "def g(w1, w2, w3, bias, resolution):\n",
    "    \n",
    "                        # Vecteur directeurs du plan\n",
    "    \n",
    "    p1 = np.array([0, -w3, w2])                     \n",
    "    p2 = np.array([-(w2*w2/w3 + w3)/w1, w2/w3, 1])\n",
    "\n",
    "    p1 = d1 * p1 / np.linalg.norm(p1, ord = 2)\n",
    "    p2 = d2 * p2 / np.linalg.norm(p2 , ord = 2)\n",
    "    \n",
    "                            # 4 coins du plan\n",
    "    \n",
    "    point2 = p1 + p2          \n",
    "    point3 = p1 - p2\n",
    "    point4 = - point2\n",
    "    point1 = - point3\n",
    "\n",
    "                    # Coordonnées pour dessiner la surface avec un grillage\n",
    "\n",
    "    L = np.linspace(0, 1, resolution)\n",
    "    L1 = []   # coordonnées x du grillage\n",
    "    L2 = []   # y\n",
    "    L3 = []   # z\n",
    "\n",
    "    for i in range(len(L)-1):\n",
    "        i = len(L)-1-i\n",
    "        L1 += [point1[0]*L[i]+point4[0]*(1-L[i]),point2[0]*L[i]+point3[0]*(1-L[i]),point2[0]*L[i-1]+point3[0]*(1-L[i-1])]\n",
    "        L2 += [point1[1]*L[i]+point4[1]*(1-L[i]),point2[1]*L[i]+point3[1]*(1-L[i]),point2[1]*L[i-1]+point3[1]*(1-L[i-1])]\n",
    "        L3 += [point1[2]*L[i]+point4[2]*(1-L[i]),point2[2]*L[i]+point3[2]*(1-L[i]),point2[2]*L[i-1]+point3[2]*(1-L[i-1])]\n",
    "        \n",
    "    L1 += [point4[0]]\n",
    "    L2 += [point4[1]]\n",
    "    L3 += [point4[2]]\n",
    "    \n",
    "    for i in range(len(L)-1):\n",
    "        i = len(L)-1-i\n",
    "        L1 += [point4[0]*L[i]+point3[0]*(1-L[i]),point1[0]*L[i]+point2[0]*(1-L[i]),point1[0]*L[i-1]+point2[0]*(1-L[i-1])]\n",
    "        L2 += [point4[1]*L[i]+point3[1]*(1-L[i]),point1[1]*L[i]+point2[1]*(1-L[i]),point1[1]*L[i-1]+point2[1]*(1-L[i-1])]\n",
    "        L3 += [point4[2]*L[i]+point3[2]*(1-L[i]),point1[2]*L[i]+point2[2]*(1-L[i]),point1[2]*L[i-1]+point2[2]*(1-L[i-1])]\n",
    "\n",
    "           # Couleurs des points (bleu si classification positive / vert sinon)\n",
    "    \n",
    "    cross_prods = np.array([np.dot(np.array([scat_x[i], scat_y[i], scat_z[i]]),np.array([w1, w2, w3])) for i in range(100)])\n",
    "    colors = np.zeros((100,3))\n",
    "    colors[np.where(cross_prods + bias < 0)] = np.array([0, 0, 255])\n",
    "    colors[np.where(cross_prods + bias >= 0)] = np.array([0, 255, 0])\n",
    "    d3plane_scat.color = colors\n",
    "    \n",
    "    \n",
    "                     # M.à.j du grillage\n",
    "    \n",
    "    d3plane_xdd.x = np.array(L1)\n",
    "    d3plane_xdd.y = np.array(L2)\n",
    "    d3plane_xdd.z = np.array(L3) - bias/w3\n",
    "    \n",
    "                    # M.à.j du vecteur orthogonal\n",
    "        \n",
    "    d3plane_vect.x, d3plane_vect.y, d3plane_vect.z = plot_3d_vector(w1, w2, w3, bias, resolution = 10, length = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "> Une autre particularité de l'algorithme du Perceptron est que la fonction de classification n'est pas tout à fait le produit scalaire avec le biais. Dans de nombreux cas, nous allons utiliser une fonction nommée d'**activation** qui va nous permettre d'utiliser une fonction de perte plus adaptée à notre problème.\n",
    ">\n",
    "> Les fonctions d'activation les plus utilisées pour l'algorithme du Perceptron sont la tangente hyperbolique **tanh** et la fonction logistique **sigmoid**.\n",
    ">\n",
    "> Supposons que les $(y_i)_{i = 1,..,n} \\in \\{-1, 1\\} $ et que nous utilisons la fonction *tanh* comme activation. La fonction de classification devient:\n",
    ">\n",
    "> $$ f(x_i, w) = tanh(\\langle x, w \\rangle + biais) $$\n",
    ">\n",
    "> La fonction de perte devient:\n",
    "> $$ g(w, X, Y) = \\sum_{i = 1}^{n} (f(x_i) - y_i)^2 $$\n",
    ">\n",
    "> La fonction de classification et la fonction de perte **ne contiennent plus de fonctions indicatrices** et sont maintenant **dérivables en tout point**. Cette nuance est très importante pour la suite. De plus, la fonction de perte est **convexe** (si les données sont linéairement séparables).\n",
    ">\n",
    "> Une autre raison pour laquelle nous utiliserions la fonction *tanh* est que\n",
    ">\n",
    "> $$ tanh(\\langle x, w \\rangle + biais) = 0 \\iff \\langle x, w \\rangle + biais = 0$$\n",
    "> car $$ tanh(x) = 0 \\iff x = 0 $$\n",
    ">\n",
    "> C'est-à-dire que l'équation de l'hyperplan séparateur optimal est la même que si nous n'utilisions pas de fonction d'activation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement par Descente de Gradient\n",
    "\n",
    "> Grâce à la fonction d'activation, la fonction de perte est dérivable. Nous pouvons utiliser un algorithme de minimisation nommée **algorithme de descente de gradient** pour trouver le vecteur $w$ optimal.\n",
    ">\n",
    "> L'algorithme de descente de gradient est très simple. Le cas le plus simple à illustrer est le cas à une dimension. Dans la figure suivante, la fonction représentée est $f(x) = x^2$ et sa dérivée est $f'(x) = 2x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide_input": false,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603bf7c278cd42abb4038458824160ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(axes=[Axis(scale=LinearScale(max=10.0, min=-10.0)), Axis(orientation='vertical', scale=LinearScale(max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa620ef351e47a58ca6e6f82f39a01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=-5.0, description='x', max=10.0, min=-10.0, step=0.2), Output()), _dom…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import bqplot.pyplot as plt\n",
    "\n",
    "xs = np.linspace(-10, 10, 100)\n",
    "ys = xs**2 + 2 #two random walks\n",
    "\n",
    "grad1_x_sc = plt.LinearScale(min = -10, max = 10)\n",
    "grad1_y_sc = plt.LinearScale(min = 0, max = 100)\n",
    "\n",
    "grad1_lines = plt.Lines(x=xs, y=ys, colors=['red'], scales = {'x': grad1_x_sc, 'y' : grad1_y_sc})\n",
    "\n",
    "grad1_label_min = plt.label([\"Minimum\"],\n",
    "                    x = [0],\n",
    "                    y = [2],\n",
    "                    scales = {'x': grad1_x_sc, 'y' : grad1_y_sc},\n",
    "                    x_offset = -30,\n",
    "                    y_offset = -15,\n",
    "                    default_size = 12,\n",
    "                    font_weight = 'bolder',\n",
    "                    update_on_move = True,\n",
    "                    colors = [\"blue\"])\n",
    "\n",
    "grad1_minimum = plt.scatter(x = [0],\n",
    "                      y = [2],\n",
    "                      colors = [\"blue\"])\n",
    "\n",
    "xk = np.random.normal(0,5,1)\n",
    "\n",
    "grad1_label_f_prim = plt.label([\" \"],\n",
    "                    x = xk,\n",
    "                    y = xk ** 2 + 2,\n",
    "                    x_offset = 0,\n",
    "                    y_offset = 0,\n",
    "                    default_size = 20,\n",
    "                    font_weight = 'bolder',\n",
    "                    update_on_move = True,\n",
    "                    colors = [\"green\"])\n",
    "\n",
    "grad1_point = plt.scatter(x = xk,\n",
    "                    y = xk ** 2 + 2,\n",
    "                    colors = [\"green\"])\n",
    "\n",
    "grad1_ax_x = bq.Axis(scale=grad1_x_sc,\n",
    "                grid_lines='solid')\n",
    "\n",
    "grad1_ax_y = bq.Axis(scale=grad1_y_sc,\n",
    "                orientation='vertical',\n",
    "                grid_lines='solid')\n",
    "\n",
    "grad1_fig = plt.Figure(marks = [grad1_lines, grad1_label_min, grad1_minimum, grad1_label_f_prim, grad1_point],\n",
    "                       axes = [grad1_ax_x, grad1_ax_y],\n",
    "                       title = \"Slope and Derivatives\")\n",
    "\n",
    "grad1_fig.layout.height = '400px'\n",
    "grad1_fig.layout.width = '600px'\n",
    "\n",
    "\n",
    "display(grad1_fig)\n",
    "\n",
    "progress.value += 1\n",
    "\n",
    "@widgets.interact(\n",
    "          x = widgets.FloatSlider(min=-10, max=10, step=0.2, value= -5))\n",
    "\n",
    "def gradient_plot(x):\n",
    "    grad1_point.x = [x]\n",
    "    grad1_point.y = [x**2 + 2]\n",
    "    \n",
    "    grad1_label_f_prim.x = [x]\n",
    "    grad1_label_f_prim.y = [x**2 + 2]\n",
    "    if(x < 0):\n",
    "        grad1_label_f_prim.text = [\"f'(x) = \" + str(2 * x) + \" < 0\"]\n",
    "        grad1_label_f_prim.x_offset = 10\n",
    "        grad1_label_f_prim.colors = [\"red\"]\n",
    "    if(x > 0):\n",
    "        grad1_label_f_prim.text = [\"f'(x) = \" + str(2 * x) + \" > 0\"]\n",
    "        grad1_label_f_prim.x_offset = - 140\n",
    "        grad1_label_f_prim.colors = [\"green\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "> Lorsque $f'(x) < 0$ (en rouge), alors $f$ est **décroissante** au voisinage de $x$.\n",
    ">\n",
    "> Lorsque $f'(x) > 0$ (en rouge), alors $f$ est **croissante** au voisinage de $x$.\n",
    ">\n",
    "> Ainsi, un point $x_{min}$ est un minimum d'une fonction **convexe** que si $f'(x_{min}) = 0$, c'est-à-dire que $f$ doit être croissante au voisinage de tout point $x > x_{min}$ et décroissante au voisinage de tout point $x < x_{min}$\n",
    ">\n",
    "> Soit $x_0$ un point aléatoire du domaine de définition de $f$. L'algorithme de descente de gradient consiste alors à choisir un point dans la direction **opposée** au gradient. C'est-à-dire que:\n",
    "> * Si $f'(x_0) < 0$, $f$ est décroissante au voisinage de $x_0$, ce qui veut dire que le minimum $x_{min}$ est forcément supérieur à $x_0$.\n",
    "> * Si $f'(x_0) > 0$, $f$ est croissante au voisinage de $x_0$, ce qui veut dire que le minimum $x_{min}$ est forcément inférieur à $x_0$.\n",
    ">\n",
    "> On définit alors $x_1 = x_0 - \\lambda f'(x_0)$, où $\\lambda$ est appelé **le pas de descente**. Dans le contexte de l'algorithme du Perceptron et du *deep learning* en général, $\\lambda$ est appelé **taux d'apprentissage** (**learning rate** en anglais).\n",
    ">\n",
    "> On répète l'opération jusqu'à obtenir un point $x_k$ tel que $f'(x_k) < tol$ où $tol$ est la **tolérance**, une constante très petite.\n",
    ">\n",
    "> > Etape 0 : Définir un point initial $x_0$ et une tolérance $tol$.\n",
    "> >\n",
    "> > Etape k : Tant que $f'(x_k) >= tol$ : $x_{k+1} = x_k - f'(x_k)$.\n",
    "\n",
    "* Que se passe-t-il lorsque le pas de descente est trop petit? Lorsqu'il est trop grand?\n",
    "\n",
    "\n",
    "* Pour l'initialisation $x_0 = -10$, trouver le plus petit pas de descente tel que $f'(x_k) \\leq 0.001$ au bout de 20 étapes.\n",
    "\n",
    "\n",
    "* Trouver un pas de descente tel que l'algorithme de descente converge vers le minimum en 1 étape pour toute initialisation $x_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234b4d6b453e45f3b8e2bfbb7d72c698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(axes=[Axis(scale=LinearScale(max=10.0, min=-10.0)), Axis(orientation='vertical', scale=L…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import bqplot.pyplot as plt\n",
    "\n",
    "xs = np.linspace(-10, 10, 100)\n",
    "ys = xs**2 + 2\n",
    "\n",
    "grad2_x_sc = plt.LinearScale(min = -10, max = 10)\n",
    "grad2_y_sc = plt.LinearScale(min = 0, max = 100)\n",
    "\n",
    "grad2_lines = plt.Lines(x=xs, y=ys, colors=['red', 'green'],scales = {'x': grad2_x_sc, 'y' : grad2_y_sc})\n",
    "\n",
    "grad2_label_min = plt.label([\"Minimum\"],\n",
    "                    x = [0],\n",
    "                    y = [2],\n",
    "                    x_offset = -30,\n",
    "                    y_offset = -15,\n",
    "                    scales = {'x': grad2_x_sc, 'y' : grad2_y_sc},\n",
    "                    default_size = 12,\n",
    "                    font_weight = 'bolder',\n",
    "                    update_on_move = True,\n",
    "                    colors = [\"blue\"])\n",
    "\n",
    "grad2_minimum = plt.Scatter(x = [0],\n",
    "                      y = [2],\n",
    "                      colors = [\"blue\"],\n",
    "                      scales = {'x': grad2_x_sc, 'y' : grad2_y_sc})\n",
    "\n",
    "xk = np.random.normal(0,5,1)\n",
    "\n",
    "grad2_label_f_prim = plt.label([\" \"],\n",
    "                    x = xk,\n",
    "                    y = xk ** 2 + 2,\n",
    "                    x_offset = 0,\n",
    "                    y_offset = 0,\n",
    "                    default_size = 20,\n",
    "                    font_weight = 'bolder',\n",
    "                    update_on_move = True,\n",
    "                    colors = [\"green\"])\n",
    "\n",
    "grad2_label_x0 = plt.label([\"x0\"],\n",
    "                    x = [-5],\n",
    "                    y = [0],\n",
    "                    x_offset = 10,\n",
    "                    y_offset = 0,\n",
    "                    default_size = 20,\n",
    "                    font_weight = 'bolder',\n",
    "                    update_on_move = True,\n",
    "                    colors = [\"red\"])\n",
    "\n",
    "grad2_lines_x0 = plt.Lines(x = [-5, -5],\n",
    "                     y = [0, 25],\n",
    "                     scales = {'x': grad2_x_sc, 'y' : grad2_y_sc},\n",
    "                     line_style = \"dashed\",\n",
    "                     colors = [\"red\"])\n",
    "\n",
    "grad2_point = plt.Scatter(x = xk,\n",
    "                    y = xk ** 2 + 2,\n",
    "                    colors = [\"green\"],\n",
    "                    scales = {'x': grad2_x_sc, 'y' : grad2_y_sc})\n",
    "\n",
    "grad2_point_lines = plt.Lines(x = xk,\n",
    "                        y = xk ** 2 + 2,\n",
    "                        colors = [\"green\"],\n",
    "                        scales = {'x': grad2_x_sc, 'y' : grad2_y_sc})\n",
    "\n",
    "grad2_ax_x = bq.Axis(scale=grad2_x_sc,\n",
    "                grid_lines='solid')\n",
    "\n",
    "grad2_ax_y = bq.Axis(scale=grad2_y_sc,\n",
    "                orientation='vertical',\n",
    "                grid_lines='solid')\n",
    "\n",
    "grad2_fig2 = plt.Figure(marks = [grad2_lines, grad2_point_lines, grad2_lines_x0,\n",
    "                                 grad2_label_min, grad2_minimum, grad2_label_f_prim,\n",
    "                                 grad2_label_x0, grad2_point],\n",
    "                        axes = [grad2_ax_x, grad2_ax_y],\n",
    "                        title = \"Convex Gradient Descent\")\n",
    "\n",
    "grad2_fig2.layout.height = '400px'\n",
    "grad2_fig2.layout.width = '600px'\n",
    "\n",
    "#display(fig2)\n",
    "\n",
    "grad2_x0 = widgets.FloatSlider(min = -10, max = 10, value = -5, step = 0.2, description = \"x0\")\n",
    "grad2_learning_rate = widgets.BoundedFloatText(min=0.001, max=1.5, step=0.01, value = 0.9, description = \"Learning rate\")\n",
    "grad2_etape_play = widgets.Play(value = 0,interval = 50, min=0, max=50, step=1, disabled=False)\n",
    "grad2_etape = widgets.IntSlider(value = 0, min = 0, max = 50, step = 1, description = \"Step\")\n",
    "grad2_hbox = widgets.HBox([grad2_etape_play,grad2_etape])\n",
    "widgets.jslink((grad2_etape_play, 'value'), (grad2_etape, 'value'))\n",
    "\n",
    "def grad2_gradient_plot(change):\n",
    "\n",
    "    xk = np.zeros(101)\n",
    "    xk[0] = grad2_x0.value\n",
    "    for k in np.arange(100)+1:\n",
    "         xk[k] = xk[k-1] - grad2_learning_rate.value*2*xk[k-1]\n",
    "    grad2_point.x = xk[:grad2_etape.value+1]\n",
    "    grad2_point.y = xk[:grad2_etape.value+1] ** 2\n",
    "        \n",
    "    grad2_point_lines.x = xk[:grad2_etape.value+1]\n",
    "    grad2_point_lines.y = xk[:grad2_etape.value+1] ** 2\n",
    "    \n",
    "    grad2_label_x0.x = [grad2_x0.value]\n",
    "    grad2_lines_x0.x = [grad2_x0.value, grad2_x0.value]\n",
    "    grad2_lines_x0.y = [0, grad2_x0.value ** 2]\n",
    "    \n",
    "    grad2_label_f_prim.x = [-8]\n",
    "    grad2_label_f_prim.y = [90]\n",
    "    grad2_label_f_prim.text = [\"Step \" + str(grad2_etape.value) + \", f'(x\"+str(grad2_etape.value)+\") = \"+str(np.round(2*xk[grad2_etape.value], 3))]\n",
    "\n",
    "grad2_etape_play.observe(grad2_gradient_plot)\n",
    "grad2_x0.observe(grad2_gradient_plot)\n",
    "grad2_learning_rate.observe(grad2_gradient_plot)\n",
    "\n",
    "display(widgets.VBox([grad2_fig2, grad2_x0, grad2_learning_rate, grad2_etape, grad2_etape_play]))\n",
    "\n",
    "progress.value += 1\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limites de la descente de gradient\n",
    "\n",
    "> Comme vous pouvez le voir, l'algorithme de descente de gradient muni du bon pas de descente est très efficace pour trouver le minimum global d'une fonction. Néanmoins, cet algorithme possède un point faible colossal: **Il n'est efficace que lorsque la fonction à minimiser est strictement convexe, ce qui n'est pas toujours le cas (comme nous allons le voir dans la suite)**.\n",
    ">\n",
    "> Dans la figure interactive suivante, nous avons tracé la fonction $f(x) = (\\frac{x}{5})^4 + (\\frac{x}{5})^3 - 6(\\frac{x}{5})^2 + 1$.\n",
    ">\n",
    "> Cette fonction contient un minimum global (celui que nous voulons approcher) et un minimum local (que nous voulons éviter).\n",
    "\n",
    "* Que se passe-t-il si nous appliquons l'algorithme de descente de gradient avec l'initialisation $x_0 = 11$ et un pas de descente de $0,1$?\n",
    "\n",
    "\n",
    "* Que se passe-t-il si nous appliquons l'algorithme de descente de gradient avec l'initialisation $x_0 = 0$ et un pas de descente quelconque?\n",
    "\n",
    "\n",
    "* Que se passe-t-il si nous appliquons l'algorithme de descente de gradient avec l'initialisation $x_0 = -1$ et un pas de descente de $0,1$?\n",
    "\n",
    "\n",
    "* Que se passe-t-il si nous appliquons l'algorithme de descente de gradient avec l'initialisation $x_0 = -1$ et un pas de descente de supérieur à $0,54$?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hide_input": false,
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e5a671109f47b09ee9905fdcba3d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(axes=[Axis(scale=LinearScale(max=15.0, min=-16.0)), Axis(orientation='vertical', scale=L…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import bqplot.pyplot as plt\n",
    "\n",
    "def f2(xs):\n",
    "    x = xs/5\n",
    "    return x**4 + x**3 - 6*x**2 + 1 \n",
    "\n",
    "def f2_p(xs):\n",
    "    x = xs/5\n",
    "    return 4*(x**3) + 3*(x)**2 - 12*x\n",
    "\n",
    "xs = np.linspace(-40, 40, 100)\n",
    "ys = f2(xs)\n",
    "\n",
    "grad3_x_sc = plt.LinearScale(min = -16, max = 15)\n",
    "grad3_y_sc = plt.LinearScale(min = -20, max = 25)\n",
    "\n",
    "grad3_lines = plt.Lines(x=xs, y=ys, colors=['red', 'green'],scales = {'x': grad3_x_sc, 'y' : grad3_y_sc})\n",
    "\n",
    "grad3_label_min_global = plt.label([\"Minimum global\"],\n",
    "                    x = [-10.7],\n",
    "                    y = [f2(-10.7)],\n",
    "                    x_offset = -30,\n",
    "                    y_offset = 15,\n",
    "                    scales = {'x': grad3_x_sc, 'y' : grad3_y_sc},\n",
    "                    default_size = 12,\n",
    "                    font_weight = 'bolder',\n",
    "                    update_on_move = True,\n",
    "                    colors = [\"blue\"])\n",
    "\n",
    "grad3_minimum_global = plt.Scatter(x = [-10.7],\n",
    "                      y = [f2(-10.7)],\n",
    "                      colors = [\"blue\"],\n",
    "                      scales = {'x': grad3_x_sc, 'y' : grad3_y_sc})\n",
    "\n",
    "grad3_label_min_local = plt.label([\"Minimum local\"],\n",
    "                    x = [7.02],\n",
    "                    y = [f2(7.02)],\n",
    "                    x_offset = -30,\n",
    "                    y_offset = 15,\n",
    "                    scales = {'x': grad3_x_sc, 'y' : grad3_y_sc},\n",
    "                    default_size = 12,\n",
    "                    font_weight = 'bolder',\n",
    "                    update_on_move = True,\n",
    "                    colors = [\"red\"])\n",
    "\n",
    "grad3_minimum_local = plt.Scatter(x = [7.02],\n",
    "                      y = [f2(7.02)],\n",
    "                      colors = [\"red\"],\n",
    "                      scales = {'x': grad3_x_sc, 'y' : grad3_y_sc})\n",
    "\n",
    "xk = np.random.normal(0,5,1)\n",
    "\n",
    "grad3_label_f_prim = plt.label([\" \"],\n",
    "                    x = xk,\n",
    "                    y = f2(xk),\n",
    "                    x_offset = 0,\n",
    "                    y_offset = 0,\n",
    "                    default_size = 20,\n",
    "                    font_weight = 'bolder',\n",
    "                    update_on_move = True,\n",
    "                    colors = [\"green\"])\n",
    "\n",
    "grad3_label_x0 = plt.label([\"x0\"],\n",
    "                    x = [-5],\n",
    "                    y = [0],\n",
    "                    x_offset = 10,\n",
    "                    y_offset = 0,\n",
    "                    default_size = 20,\n",
    "                    font_weight = 'bolder',\n",
    "                    update_on_move = True,\n",
    "                    colors = [\"red\"])\n",
    "\n",
    "grad3_lines_x0 = plt.Lines(x = [-5, -5],\n",
    "                     y = [0, 25],\n",
    "                     scales = {'x': grad3_x_sc, 'y' : grad3_y_sc},\n",
    "                     line_style = \"dashed\",\n",
    "                     colors = [\"red\"])\n",
    "\n",
    "grad3_point = plt.Scatter(x = xk,\n",
    "                    y = f2(xk),\n",
    "                    colors = [\"green\"],\n",
    "                    scales = {'x': grad3_x_sc, 'y' : grad3_y_sc})\n",
    "\n",
    "grad3_point_lines = plt.Lines(x = xk,\n",
    "                        y = f2(xk),\n",
    "                        colors = [\"green\"],\n",
    "                        scales = {'x': grad3_x_sc, 'y' : grad3_y_sc})\n",
    "\n",
    "grad3_ax_x = bq.Axis(scale=grad3_x_sc,\n",
    "                grid_lines='solid')\n",
    "\n",
    "grad3_ax_y = bq.Axis(scale=grad3_y_sc,\n",
    "                orientation='vertical',\n",
    "                grid_lines='solid')\n",
    "\n",
    "grad3_fig2 = plt.Figure(marks = [grad3_lines, grad3_point_lines, grad3_lines_x0,\n",
    "                                 grad3_label_min_global, grad3_minimum_global, grad3_label_f_prim,\n",
    "                                 grad3_label_min_local, grad3_minimum_local,\n",
    "                                 grad3_label_x0, grad3_point],\n",
    "                        axes = [grad3_ax_x, grad3_ax_y],\n",
    "                        title = \"Non-Convex Gradient Descent\")\n",
    "\n",
    "grad3_fig2.layout.height = '400px'\n",
    "grad3_fig2.layout.width = '600px'\n",
    "\n",
    "#display(fig2)\n",
    "\n",
    "grad3_x0 = widgets.FloatSlider(min = -15, max = 11, value = -5, step = 1, description = \"x0\")\n",
    "grad3_learning_rate = widgets.BoundedFloatText(min=0.001, max=0.6, step=0.01, value = 0.1, description = \"Learning rate\")\n",
    "grad3_etape_play = widgets.Play(value = 0,interval = 300, min=0, max=50, step=1, disabled=False)\n",
    "grad3_etape = widgets.IntSlider(value = 0, min = 0, max = 50, step = 1, description = \"Step\")\n",
    "grad3_hbox = widgets.HBox([grad3_etape_play,grad3_etape])\n",
    "widgets.jslink((grad3_etape_play, 'value'), (grad3_etape, 'value'))\n",
    "\n",
    "def gradient_plot2(change):\n",
    "\n",
    "    xk = np.zeros(101)\n",
    "    xk[0] = grad3_x0.value\n",
    "    for k in np.arange(100)+1:\n",
    "         xk[k] = xk[k-1] - grad3_learning_rate.value*f2_p(xk[k-1])\n",
    "    grad3_point.x = xk[:grad3_etape.value+1]\n",
    "    grad3_point.y = f2(xk[:grad3_etape.value+1])\n",
    "        \n",
    "    grad3_point_lines.x = xk[:grad3_etape.value+1]\n",
    "    grad3_point_lines.y = f2(xk[:grad3_etape.value+1])\n",
    "    \n",
    "    grad3_label_x0.x = [grad3_x0.value]\n",
    "    grad3_lines_x0.x = [grad3_x0.value, grad3_x0.value]\n",
    "    grad3_lines_x0.y = [0, f2(grad3_x0.value)]\n",
    "    \n",
    "    grad3_label_f_prim.x = [-14]\n",
    "    grad3_label_f_prim.y = [22]\n",
    "    grad3_label_f_prim.text = [\"Step \" + str(grad3_etape.value) + \", f'(x\"+str(grad3_etape.value)+\") = \"+str(np.round(f2_p(xk[grad3_etape.value]), 3))]\n",
    "\n",
    "grad3_etape_play.observe(gradient_plot2)\n",
    "grad3_x0.observe(gradient_plot2)\n",
    "grad3_learning_rate.observe(gradient_plot2)\n",
    "\n",
    "display(widgets.VBox([grad3_fig2, grad3_x0, grad3_learning_rate, grad3_etape, grad3_etape_play]))\n",
    "\n",
    "progress.value += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "> Lorsque la fonction à minimiser n'est pas convexe, l'algorithme de descente de gradient devient imprévisible et ne donne pas de résultats consistants. **Les résultats de l'algorithme sont très sensibles au variation du pas du gradient**.\n",
    ">\n",
    "> Dans la grande majorité des cas en *deep learning*, **la fonction de perte à minimiser n'est jamais convexe et l'algorithme de descente de gradient convergera vers un minimum local**.\n",
    ">\n",
    "> Malheureusement, l'algorithme de descente de gradient est l'un des seuls algorithmes pouvant être utilisés en pratique car il est le seul algorithme d'optimisation efficace en temps de calcul dont nous disposons.\n",
    ">\n",
    ">\n",
    "> Comme vous le verrez plus tard dans des modules pratiques, **le pas du gradient est l'un des hyperparamètres les plus influents sur la performance d'un modèle de *deep learning***.\n",
    "\n",
    "### Perceptron Multicouche\n",
    "\n",
    "> L'algorithme de Perceptron simple n'est plus utilisé en pratique. L'algorithme du ***Support Vector Machine***, aussi connu sous le nom de **Perceptron à stabilité optimale**, est bien plus performant.\n",
    ">\n",
    "> L'interêt de l'algorithme du Perceptron vient d'une technique démontrée en 1989 par George Cybenko qui consiste à empiler plusieurs perceptrons qui auront la même entrée sur une couche appelée **couche cachée** (*hidden layer* en anglais). \n",
    ">\n",
    "> La sortie de cette couche de perceptrons sera ensuite donnée en entrée à un perceptron qui fera la classification binaire. Ce perceptron forme ce que l'on appelle la **couche de sortie** (*output layer* en anglais).\n",
    ">\n",
    "> Un algorithme de ce type s'appelle **Perceptron Multicouche** (*Multilayer Perceptron* en anglais), souvent abrégé par l'acronyme **MLP**.\n",
    ">\n",
    "> Dans l'exemple suivant, nous illustrons un MLP avec une couche cachée de 3 perceptrons et une couche de sortie à 1 perceptron. Vous pouvez appuyer sur le bouton *play* pour lancer l'animation, et le bouton *stop* pour la relancer depuis le début."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5ae540be1c4ff0adb10cd873ed145e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(animation_duration=1000, fig_margin={'top': 60, 'bottom': 60, 'left': 60, 'right': 60}, marks=[Label(co…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b04f15fad5a4d389f9157a054a052fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Play(value=0, description='frame', interval=2000, max=9), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clear()\n",
    "\n",
    "mlp_x_sc = plt.LinearScale(min = -1, max = 6)\n",
    "mlp_y_sc = plt.LinearScale(min = -5, max = 5)\n",
    "\n",
    "mlp_ax_x = bq.Axis(scale= mlp_x_sc)\n",
    "\n",
    "mlp_ax_y = bq.Axis(scale= mlp_y_sc, orientation='vertical')\n",
    "\n",
    "mlp_point1 = plt.Scatter(x = [0], y = [0], scales = {'x': mlp_x_sc, 'y': mlp_y_sc})\n",
    "\n",
    "mlp_point2 = plt.Scatter(x = [0], y = [0], scales = {'x': mlp_x_sc, 'y': mlp_y_sc})\n",
    "\n",
    "mlp_point3 = plt.Scatter(x = [0], y = [0], scales = {'x': mlp_x_sc, 'y': mlp_y_sc})\n",
    "\n",
    "mlp_input_label = plt.Label(text = ['Input'], x = [0], y = [4],\n",
    "                            scales = {'x': mlp_x_sc, 'y' : mlp_y_sc},\n",
    "                            default_size = 12,\n",
    "                            default_opacities = [0.5],\n",
    "                            font_weight = 'bolder',\n",
    "                            update_on_move = True,\n",
    "                            colors = [\"blue\"])\n",
    "\n",
    "mlp_input_layer_label = plt.Label(text = ['Input Layer'], x = [-0.8], y = [-5],\n",
    "                                  scales = {'x': mlp_x_sc, 'y' : mlp_y_sc},\n",
    "                                  default_size = 20,\n",
    "                                  default_opacities = [0.9],\n",
    "                                  font_weight = 'bolder',\n",
    "                                  update_on_move = True,\n",
    "                                  colors = [\"steelblue\"])\n",
    "\n",
    "mlp_hidden_layer_label = plt.Label(text = ['Hidden Layer'], x = [1.1], y = [-5],\n",
    "                                   scales = {'x': mlp_x_sc, 'y' : mlp_y_sc},\n",
    "                                   default_size = 20,\n",
    "                                   default_opacities = [0.65],\n",
    "                                   font_weight = 'bolder',\n",
    "                                   update_on_move = True,\n",
    "                                   colors = [\"red\"])\n",
    "\n",
    "mlp_out_layer_label = plt.Label(text = ['Output Layer'], x = [4.1], y = [-5],\n",
    "                                   scales = {'x': mlp_x_sc, 'y' : mlp_y_sc},\n",
    "                                   default_size = 20,\n",
    "                                   default_opacities = [0.65],\n",
    "                                   font_weight = 'bolder',\n",
    "                                   update_on_move = True,\n",
    "                                   colors = [\"green\"])\n",
    "\n",
    "mlp_dotprod1_label = plt.Label(text = ['Dot Product 1'], x = [2], y = [4],\n",
    "                               scales = {'x': mlp_x_sc, 'y' : mlp_y_sc},\n",
    "                               default_size = 12,\n",
    "                               default_opacities = [0.5],\n",
    "                               font_weight = 'bolder',\n",
    "                               update_on_move = True,\n",
    "                               colors = [\"blue\"])\n",
    "\n",
    "mlp_dotprod2_label = plt.Label(text = ['Dot Product 2'], x = [2], y = [4],\n",
    "                               scales = {'x': mlp_x_sc, 'y' : mlp_y_sc},\n",
    "                               default_size = 12,\n",
    "                               default_opacities = [0.5],\n",
    "                               font_weight = 'bolder',\n",
    "                               update_on_move = True,\n",
    "                               colors = [\"blue\"])\n",
    "\n",
    "mlp_activ1_label = plt.Label(text = [\"Activation 1\"], x = [3], y = [4],\n",
    "                             scales = {'x': mlp_x_sc, 'y' : mlp_y_sc},\n",
    "                             default_size = 12,\n",
    "                             default_opacities = [0.5],\n",
    "                             font_weight = 'bolder',\n",
    "                             update_on_move = True,\n",
    "                             colors = [\"blue\"])\n",
    "\n",
    "mlp_activ2_label = plt.Label(text = [\"Activation 2\"], x = [3], y = [4],\n",
    "                           scales = {'x': mlp_x_sc, 'y' : mlp_y_sc},\n",
    "                           default_size = 12,\n",
    "                           default_opacities = [0.5],\n",
    "                           font_weight = 'bolder',\n",
    "                           update_on_move = True,\n",
    "                           opacity = [0.5],\n",
    "                           colors = [\"blue\"])\n",
    "\n",
    "mlp_conc_label = plt.Label(text = [\"Concatenation of Outputs\"], x = [4], y = [4],\n",
    "                           scales = {'x': mlp_x_sc, 'y' : mlp_y_sc},\n",
    "                           default_size = 12,\n",
    "                           default_opacities = [0.5],\n",
    "                           font_weight = 'bolder',\n",
    "                           update_on_move = True,\n",
    "                           colors = [\"blue\"])\n",
    "\n",
    "mlp_class_label = plt.Label(text = [\"Classification\"], x = [5], y = [4],\n",
    "                           scales = {'x': mlp_x_sc, 'y' : mlp_y_sc},\n",
    "                           default_size = 12,\n",
    "                           default_opacities = [0.5],\n",
    "                           font_weight = 'bolder',\n",
    "                           update_on_move = True,\n",
    "                           colors = [\"blue\"])\n",
    "\n",
    "mlp_perceptrons = plt.Scatter(x = [0, 2, 2, 2, 5],\n",
    "                              y = [0, -3.5, 0, 3.5, 0],\n",
    "                              size = [900, 900 , 900, 900, 900],\n",
    "                              default_size = 900,\n",
    "                              colors = ['steelblue','red', 'red', 'red', 'green'],\n",
    "                              scales = {'x': mlp_x_sc, 'y': mlp_y_sc})\n",
    "\n",
    "mlp_arete1_1 = plt.Scatter(x = np.zeros(80),\n",
    "                         y = np.zeros(80),\n",
    "                         size = [10, 10, 10],\n",
    "                         default_size = 10,\n",
    "                         scales = {'x': mlp_x_sc, 'y': mlp_y_sc})\n",
    "\n",
    "mlp_arete1_2 = plt.Scatter(x = np.zeros(80),\n",
    "                         y = np.zeros(80),\n",
    "                         size = [10, 10, 10],\n",
    "                         default_size = 10,\n",
    "                         scales = {'x': mlp_x_sc, 'y': mlp_y_sc})\n",
    "\n",
    "mlp_arete1_3 = plt.Scatter(x = np.zeros(80),\n",
    "                         y = np.zeros(80),\n",
    "                         size = [10, 10, 10],\n",
    "                         default_size = 10,\n",
    "                         scales = {'x': mlp_x_sc, 'y': mlp_y_sc})\n",
    "\n",
    "mlp_arete2_1 = plt.Scatter(x = np.zeros(100) + 2,\n",
    "                          y = np.zeros(100) + 3.5,\n",
    "                          colors = ['red'],\n",
    "                          size = [10, 10, 10],\n",
    "                          default_size = 10,\n",
    "                          scales = {'x': mlp_x_sc, 'y': mlp_y_sc})\n",
    "\n",
    "mlp_arete2_2 = plt.Scatter(x = np.zeros(100) + 2 ,\n",
    "                          y = np.zeros(100),\n",
    "                          colors = ['red'],\n",
    "                          size = [10, 10, 10],\n",
    "                          default_size = 10,\n",
    "                          scales = {'x': mlp_x_sc, 'y': mlp_y_sc})\n",
    "\n",
    "mlp_arete2_3 = plt.Scatter(x = np.zeros(100) + 2,\n",
    "                           y = np.zeros(100) - 3.5,\n",
    "                           colors = ['red'],\n",
    "                           size = [10, 10, 10],\n",
    "                           default_size = 10,\n",
    "                           scales = {'x': mlp_x_sc, 'y': mlp_y_sc})\n",
    "\n",
    "mlp_arete3_1 = plt.Scatter(x = np.zeros(50) + 5,\n",
    "                           y = np.zeros(50) ,\n",
    "                           colors = ['green'],\n",
    "                           size = [10, 10, 10],\n",
    "                           default_size = 10,\n",
    "                           scales = {'x': mlp_x_sc, 'y': mlp_y_sc})\n",
    "\n",
    "\n",
    "\n",
    "mlp_fig = plt.Figure(marks = [mlp_input_layer_label, mlp_hidden_layer_label,mlp_out_layer_label,\n",
    "                              mlp_arete1_1,mlp_arete1_2, mlp_arete1_3,\n",
    "                              mlp_arete2_1, mlp_arete2_2, mlp_arete2_3,\n",
    "                              mlp_arete3_1,\n",
    "                              mlp_perceptrons, mlp_point1, mlp_point2, mlp_point3, \n",
    "                              mlp_input_label, mlp_dotprod1_label, mlp_dotprod2_label,\n",
    "                              mlp_activ1_label, mlp_conc_label, mlp_activ2_label,\n",
    "                              mlp_class_label],\n",
    "                     #axes = [mlp_ax_x, mlp_ax_y],\n",
    "                     animation_duration = 1000)\n",
    "\n",
    "####################################################\n",
    "mlp_activ2_label.x = [4.5]\n",
    "mlp_activ2_label.y = [2]\n",
    "mlp_activ2_label.default_opacities = [0.01]\n",
    "mlp_activ2_label.opacity = [0.01]\n",
    "\n",
    "mlp_dotprod2_label.x = [4]\n",
    "mlp_dotprod2_label.y = [2]\n",
    "mlp_dotprod2_label.default_opacities = [0.01]\n",
    "mlp_dotprod2_label.opacity = [0.01]\n",
    "\n",
    "mlp_conc_label.x = [2.4]\n",
    "mlp_conc_label.y = [3]\n",
    "mlp_conc_label.default_opacities = [0.01]\n",
    "mlp_conc_label.opacity = [0.01]\n",
    "\n",
    "mlp_activ1_label.x = [1.6]\n",
    "mlp_activ1_label.y = [5]\n",
    "mlp_activ1_label.default_opacities = [0.01]\n",
    "mlp_activ1_label.opacity = [0.01]\n",
    "\n",
    "mlp_input_label.x = [-0.2]\n",
    "mlp_input_label.y = [2]\n",
    "mlp_input_label.default_opacities = [0.01]\n",
    "mlp_input_label.opacity = [0.01]\n",
    "\n",
    "mlp_dotprod1_label.x = [0.5]\n",
    "mlp_dotprod1_label.y = [4.2]\n",
    "mlp_dotprod1_label.default_opacities = [0.01]\n",
    "mlp_dotprod1_label.opacity = [0.01]\n",
    "\n",
    "mlp_class_label.x = [5]\n",
    "mlp_class_label.y = [2]\n",
    "mlp_class_label.default_opacities = [0.01]\n",
    "mlp_class_label.opacity = [0.01]\n",
    "\n",
    "display(mlp_fig)\n",
    "\n",
    "progress.value += 1\n",
    "@widgets.interact(frame = widgets.Play(value = 0, interval = 2000, min = 0, max = 9, step=1, disabled=False))\n",
    "\n",
    "def mlp_anim(frame):\n",
    "    if(frame == 0):\n",
    "        mlp_class_label.default_opacities = [0.01]\n",
    "        mlp_class_label.opacity = [0.01]\n",
    "        \n",
    "        mlp_input_label.default_opacities = [0.9]\n",
    "        mlp_input_label.opacity = [0.9]\n",
    "        \n",
    "        mlp_arete1_1.x = np.zeros(80)\n",
    "        mlp_arete1_1.y = np.zeros(80)\n",
    "        \n",
    "        mlp_arete1_2.x = np.zeros(80)\n",
    "        mlp_arete1_2.y = np.zeros(80)\n",
    "        \n",
    "        mlp_arete1_3.x = np.zeros(80)\n",
    "        mlp_arete1_3.y = np.zeros(80)\n",
    "        \n",
    "        mlp_arete2_1.x = np.zeros(100) + 2\n",
    "        mlp_arete2_1.y = np.zeros(100) + 3.5\n",
    "\n",
    "        mlp_arete2_2.x = np.zeros(100) + 2\n",
    "        mlp_arete2_2.y = np.zeros(100)\n",
    "\n",
    "        mlp_arete2_3.x = np.zeros(100) + 2\n",
    "        mlp_arete2_3.y = np.zeros(100) - 3.5\n",
    "        \n",
    "        mlp_arete3_1.x = np.zeros(100) + 5\n",
    "        mlp_arete3_1.y = np.zeros(100)\n",
    "        \n",
    "        mlp_point1.x, mlp_point1.y = [0], [0]\n",
    "        mlp_point2.x, mlp_point2.y = [0], [0]\n",
    "        mlp_point3.x, mlp_point3.y = [0], [0]\n",
    "        \n",
    "        mlp_point1.names = ['x']\n",
    "        mlp_point2.names = ['x']\n",
    "        mlp_point3.names = ['x']\n",
    "        \n",
    "        mlp_point1.colors = ['steelblue']\n",
    "        mlp_point2.colors = ['steelblue']\n",
    "        mlp_point3.colors = ['steelblue']\n",
    "        return\n",
    "    if(frame == 1):\n",
    "        mlp_input_label.default_opacities = [0.01]\n",
    "        mlp_input_label.opacity = [0.01]\n",
    "        \n",
    "        mlp_dotprod1_label.default_opacities = [0.9]\n",
    "        mlp_dotprod1_label.opacity = [0.9]\n",
    "        \n",
    "        mlp_arete1_1.x = np.append(np.linspace(0, 1, 50), np.zeros(30) + 1)\n",
    "        mlp_arete1_1.y = np.append(np.linspace(0, 1.75, 50), np.zeros(30) + 1.75)\n",
    "        \n",
    "        \n",
    "        mlp_arete1_2.x = np.append(np.linspace(0, 1, 50), np.zeros(30) + 1)\n",
    "        \n",
    "        mlp_arete1_3.x = np.append(np.linspace(0, 1, 50), np.zeros(30) + 1)\n",
    "        mlp_arete1_3.y = np.append(np.linspace(0, -1.75, 50), np.zeros(30) - 1.75)\n",
    "        \n",
    "        mlp_point1.x, mlp_point1.y = [1], [1.75]\n",
    "        mlp_point2.x, mlp_point2.y = [1], [0]\n",
    "        mlp_point3.x, mlp_point3.y = [1], [-1.75]\n",
    "        \n",
    "        mlp_point1.names = ['<w1, x> + b1']\n",
    "        mlp_point2.names = ['<w2, x> + b2']\n",
    "        mlp_point3.names = ['<w3, x> + b3']\n",
    "        return\n",
    "    if(frame == 2):\n",
    "        \n",
    "        mlp_dotprod1_label.default_opacities = [0.01]\n",
    "        mlp_dotprod1_label.opacity = [0.01]\n",
    "        \n",
    "        mlp_activ1_label.default_opacities = [0.9]\n",
    "        mlp_activ1_label.opacity = [0.9]\n",
    "        \n",
    "        mlp_arete1_1.x = np.append(np.linspace(0, 1, 50), np.linspace(1,2, 30))\n",
    "        mlp_arete1_1.y = np.append(np.linspace(0, 1.75, 50), np.linspace(1.75, 3.5, 30))\n",
    "        \n",
    "        mlp_arete1_2.x = np.append(np.linspace(0, 1, 50), np.linspace(1,2, 30))\n",
    "        \n",
    "        \n",
    "        mlp_arete1_3.x = np.append(np.linspace(0, 1, 50), np.linspace(1,2, 30))\n",
    "        mlp_arete1_3.y = np.append(np.linspace(0, -1.75, 50), np.linspace(-1.75, -3.5, 30))\n",
    "        \n",
    "        mlp_point1.x, mlp_point1.y = [2], [3.5]\n",
    "        mlp_point2.x, mlp_point2.y = [2], [0]\n",
    "        mlp_point3.x, mlp_point3.y = [2], [-3.5]\n",
    "        \n",
    "        mlp_point1.names = [' ']\n",
    "        mlp_point2.names = [' ']\n",
    "        mlp_point3.names = [' ']\n",
    "        return\n",
    "    if(frame == 3):\n",
    "        mlp_point1.colors = ['red']\n",
    "        mlp_point2.colors = ['red']\n",
    "        mlp_point3.colors = ['red']\n",
    "        \n",
    "        \n",
    "        return\n",
    "    if(frame == 4):\n",
    "        mlp_activ1_label.default_opacities = [0.01]\n",
    "        mlp_activ1_label.opacity = [0.01]\n",
    "        \n",
    "        mlp_conc_label.default_opacities = [0.9]\n",
    "        mlp_conc_label.opacity = [0.9]\n",
    "        \n",
    "        mlp_point1.names = ['O1']\n",
    "        mlp_point2.names = ['O2']\n",
    "        mlp_point3.names = ['O3']\n",
    "\n",
    "        mlp_point1.x, mlp_point1.y = [3], [1]\n",
    "        mlp_point2.x, mlp_point2.y = [3], [0]\n",
    "        mlp_point3.x, mlp_point3.y = [3], [-1]\n",
    "        return\n",
    "    if(frame == 5):\n",
    "        mlp_point1.x, mlp_point1.y = [4], [0]\n",
    "        mlp_point2.x, mlp_point2.y = [4], [0]\n",
    "        mlp_point3.x, mlp_point3.y = [4], [0]\n",
    "        \n",
    "        mlp_arete2_1.x = np.append(np.linspace(2, 4, 50), np.zeros(50) + 4)\n",
    "        mlp_arete2_1.y = np.append(np.linspace(3.5, 0, 50), np.zeros(50))\n",
    "        \n",
    "        \n",
    "        mlp_arete2_2.x = np.append(np.linspace(2, 4, 50), np.zeros(50) + 4)\n",
    "        \n",
    "        mlp_arete2_3.x = np.append(np.linspace(2, 4, 50), np.zeros(50) + 4)\n",
    "        mlp_arete2_3.y = np.append(np.linspace(-3.5, 0, 50), np.zeros(50))\n",
    "        \n",
    "        mlp_point1.names = ['O']\n",
    "        mlp_point2.names = ['O']\n",
    "        mlp_point3.names = ['O']\n",
    "        return\n",
    "    if(frame == 6):\n",
    "        mlp_conc_label.default_opacities = [0.01]\n",
    "        mlp_conc_label.opacity = [0.01]\n",
    "        \n",
    "        mlp_dotprod2_label.default_opacities = [0.9]\n",
    "        mlp_dotprod2_label.opacity = [0.9]\n",
    "        \n",
    "        mlp_point1.x, mlp_point1.y = [4.5], [0]\n",
    "        mlp_point2.x, mlp_point2.y = [4.5], [0]\n",
    "        mlp_point3.x, mlp_point3.y = [4.5], [0]\n",
    "        \n",
    "        mlp_arete2_1.x = np.append(np.linspace(2, 4, 50), np.linspace(4, 5, 50))\n",
    "        mlp_arete2_1.y = np.append(np.linspace(3.5, 0, 50), np.zeros(50))\n",
    "        \n",
    "        \n",
    "        mlp_arete2_2.x = np.append(np.linspace(2, 4, 50), np.linspace(4, 5, 50))\n",
    "        \n",
    "        mlp_arete2_3.x = np.append(np.linspace(2, 4, 50), np.linspace(4, 5, 50))\n",
    "        mlp_arete2_3.y = np.append(np.linspace(-3.5, 0, 50), np.zeros(50))\n",
    "\n",
    "        mlp_point1.names = ['<w4, O> + b4']\n",
    "        mlp_point2.names = ['<w4, O> + b4']\n",
    "        mlp_point3.names = ['<w4, O> + b4']\n",
    "        return\n",
    "    if(frame == 7):\n",
    "        mlp_dotprod2_label.default_opacities = [0.01]\n",
    "        mlp_dotprod2_label.opacity = [0.01]\n",
    "        \n",
    "        mlp_activ2_label.default_opacities = [0.9]\n",
    "        mlp_activ2_label.opacity = [0.9]\n",
    "        \n",
    "        mlp_point1.x, mlp_point1.y = [5], [0]\n",
    "        mlp_point2.x, mlp_point2.y = [5], [0]\n",
    "        mlp_point3.x, mlp_point3.y = [5], [0]\n",
    "        \n",
    "        mlp_point1.names = [' ']\n",
    "        mlp_point2.names = [' ']\n",
    "        mlp_point3.names = [' ']\n",
    "        return\n",
    "    if(frame == 8):\n",
    "        \n",
    "        mlp_point1.colors = ['green']\n",
    "        mlp_point2.colors = ['green']\n",
    "        mlp_point3.colors = ['green']\n",
    "        return        \n",
    "    if(frame == 9):\n",
    "        mlp_activ2_label.default_opacities = [0.01]\n",
    "        mlp_activ2_label.opacity = [0.01]\n",
    "        \n",
    "        mlp_class_label.default_opacities = [0.9]\n",
    "        mlp_class_label.opacity = [0.9]\n",
    "        \n",
    "        if(np.random.normal(0,1,1) > 0):\n",
    "            mlp_point1.x, mlp_point1.y = [5.5], [0]\n",
    "            mlp_point2.x, mlp_point2.y = [5.5], [0]\n",
    "            mlp_point3.x, mlp_point3.y = [5.5], [0]\n",
    "            \n",
    "            mlp_arete3_1.x = np.linspace(5, 5.5, 50)\n",
    "            mlp_arete3_1.y = np.zeros(50)\n",
    "            \n",
    "            mlp_point1.names = ['1']\n",
    "            mlp_point2.names = ['1']\n",
    "            mlp_point3.names = ['1']\n",
    "        else:\n",
    "            mlp_point1.x, mlp_point1.y = [5.5], [0]\n",
    "            mlp_point2.x, mlp_point2.y = [5.5], [0]\n",
    "            mlp_point3.x, mlp_point3.y = [5.5], [0]\n",
    "            \n",
    "            mlp_arete3_1.x = np.linspace(5, 5.5, 50)\n",
    "            mlp_arete3_1.y = np.zeros(50)\n",
    "            \n",
    "            mlp_point1.names = ['0']\n",
    "            mlp_point2.names = ['0']\n",
    "            mlp_point3.names = ['0']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "> Dans un problème de classification, ce type d'algorithme permet d'approximer une frontière de décision non-linéaire, mais pour cela **il faut absolument que les fonctions d'activations des perceptrons de la couche cachée soient non-linéaires**. En pratique, nous utiliserons les fonctions $tanh$ ou $ReLU$ définie par ${ReLU(x) = \\begin{cases} x & \\mbox{si } x \\geq 0 \\\\ 0 & \\mbox{sinon }\\end{cases}}$.\n",
    ">\n",
    "> Pour illustrer les effets de ces fonctions d'activation, nous allons appliquer l'algorithme du MLP sur le dataset *moons*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8feed59462714902818b509bf612e0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(axes=[Axis(label='x', scale=LinearScale(max=2.0, min=-1.0)), Axis(label='y', orientation='vertical', sc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples = 100)\n",
    "\n",
    "X_0 = X[y == 0]\n",
    "X_1 = X[y == 1]\n",
    "\n",
    "# Scales\n",
    "\n",
    "moons_x_sc= plt.LinearScale(min = -1, max = 2)\n",
    "\n",
    "moons_y_sc= plt.LinearScale(min = -1, max = 1)\n",
    "\n",
    "# Axes\n",
    "\n",
    "moons_ax_x = plt.Axis(scale = moons_x_sc,\n",
    "                      grid_lines = 'solid',\n",
    "                      label ='x')\n",
    "\n",
    "moons_ax_y = plt.Axis(scale = moons_y_sc,\n",
    "                      grid_lines = 'solid',\n",
    "                      orientation = 'vertical',\n",
    "                      label = 'y')\n",
    "\n",
    "# Scatter plots\n",
    "\n",
    "moons_x0 = plt.Scatter(x = X_0[:,0], y = X_0[:,1],\n",
    "                       scales = {'x': moons_x_sc, 'y': moons_y_sc},\n",
    "                       colors = ['blue'])\n",
    "\n",
    "moons_x1 = plt.Scatter(x = X_1[:,0], y = X_1[:,1],\n",
    "                       scales = {'x': moons_x_sc, 'y': moons_y_sc},\n",
    "                       colors = ['red'])\n",
    "\n",
    "# Figure\n",
    "\n",
    "moons_fig = plt.Figure(marks = [moons_x0, moons_x1],\n",
    "                       axes = [moons_ax_x, moons_ax_y],\n",
    "                       title = \"Moons Dataset\")\n",
    "\n",
    "moons_fig.layout.height = '400px'\n",
    "moons_fig.layout.width = '500px'\n",
    "\n",
    "progress.value += 1\n",
    "display(moons_fig)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Nous nous apercevons rapidement que cette base de données n'est pas linéairement séparable. Pour ce type de données, aucun algorithme de Perceptron simple n'arrivera à trouver une solution satisfaisante.\n",
    ">\n",
    ">Néanmoins, grâce au modèle MLP nous pouvons approximer une frontière de décision non-linéaire. Dans la figure interactive ci- dessous, les points bleus et rouges représentent les deux classes d'individus et la ligne de couleur verte correspond à l'approximation de la frontière de décision obtenue par descente de gradient avec un maximum de $1 000 000$ d'itérations.\n",
    "\n",
    "* A l'aide du menu interactif, déterminer le meilleur pas de gradient pour un MLP ayant 3 perceptrons dans sa couche cachée et utilisant la fonction $ReLU$ comme activation.\n",
    "\n",
    "\n",
    "* Pourquoi le MLP ayant 3 perceptrons dans sa couche cachée et utilisant la fonction $tanh$ comme activation ne trouve pas de frontière de décision satisfaisante pour un pas de gradient inférieur ou égal à $0.01$?\n",
    "\n",
    "\n",
    "* Pour quelle raison le MLP ayant 30 perceptrons dans sa couche cachée et utilisant la fonction $ReLU$ comme activation est plus performant que le MLP ayant 90 perceptrons dans sa couche cachée et utilisant la fonction $ReLU$ comme activation lorsque le pas de gradient est fixé à $1$?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hide_input": false,
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a29bf7d054e46a9a212ed1084a17aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(animation_duration=500, axes=[Axis(label='x', scale=LinearScale(max=2.0, min=-1.0)), Axis(label='y', or…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5800f845767e4267aaa8ba8698fb9604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Activation Function', options=('relu', 'tanh'), style=DescriptionS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json as json\n",
    "\n",
    "with open('decision_boundaries.txt') as json_file:\n",
    "    decision_boundaries2 = json.load(json_file)\n",
    "    \n",
    "db = np.sort(np.array(decision_boundaries2['relu']['3']['1']), axis = 0)\n",
    "moons_db = plt.Scatter(x = db[:,0],\n",
    "                       y = db[:,1],\n",
    "                       scales = {'x': moons_x_sc, 'y': moons_y_sc},\n",
    "                       default_size = 4,\n",
    "                       size = [3],\n",
    "                       colors = ['green'])\n",
    "\n",
    "moons_fig2 = plt.Figure(marks = [moons_x0, moons_x1, moons_db],\n",
    "                        axes = [moons_ax_x, moons_ax_y],\n",
    "                        animation_duration = 500,\n",
    "                        title = \"Decision Boundaries on Moons Dataset\")\n",
    "moons_fig2.layout.height = '400px'\n",
    "moons_fig2.layout.width = '500px'\n",
    "\n",
    "progress.value += 1\n",
    "\n",
    "display(moons_fig2)\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "@widgets.interact(activation = widgets.Dropdown(options=['relu', 'tanh'],\n",
    "                                              value='relu',\n",
    "                                              description='Activation Function',\n",
    "                                              disabled = False,\n",
    "                                              style = style),\n",
    "                  n_layers = widgets.Dropdown(options=['2', '3', '30', '90'],\n",
    "                                              value='3',\n",
    "                                              description='Hidden Layer Size',\n",
    "                                              style = style,\n",
    "                                              disabled = False),\n",
    "                  learning_rate = widgets.Dropdown(options=['0.001', '0.01', '0.1', '1'],\n",
    "                                              value='0.001',\n",
    "                                              description='Learning Rate',\n",
    "                                              style = style,\n",
    "                                              disabled = False)\n",
    "                  )\n",
    "def moons_interaction(activation,n_layers,learning_rate):\n",
    "    db = np.array(decision_boundaries2[activation][n_layers][learning_rate])\n",
    "    \n",
    "    moons_db.x = db[:,0]\n",
    "    moons_db.y = db[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Le comportement de la descente de gradient est imprévisible car la fonction de perte n'est pas convexe. Un pas de gradient trop grand ou trop petit ne permettra pas à l'algorithme de converger vers une solution satisfaisante, même si la solution existe.\n",
    "\n",
    "### Ce qu'il faut retenir:\n",
    "> * Le produit scalaire est le principal outil que nous utilisons pour faire la classification. **Cette classification est purement géométrique**.\n",
    "> * L'objectif d'un Perceptron est de **trouver un hyperplan qui sépare les différentes classes d'individus**. \n",
    "> * L'atteinte de cet objectif se fait en **minimisant la fonction de perte par descente de gradient**.\n",
    "> * Si la base de données n'est pas linéairement séparable, il n'existe pas forcément un unique minimum global.\n",
    "> * Si la base de données n'est pas linéairement séparable, **il est quand même possible de trouver un hyperplan séparateur non-linéaire en utilisant une approche multicouche.**\n",
    "> * **Un pas de gradient trop grand ou trop petit ne permettra pas à l'algorithme MLP de converger vers une solution satisfaisante**. Trouver le bon pas de gradient et la bonne initialisation est tout le challenge du *deep learning*.\n",
    "\n",
    "\n",
    "### Fin\n",
    "\n",
    "> Merci d'avoir suivi cet exercice introductif sur le *deep learning*! Le prochain exercice traitera sur différents types de couche plus avancés que le MLP et très utilisés aujourd'hui dans les algorithmes *state-of-the-art* de *deep learning*."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Éditer les Méta-Données",
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
